{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8",
   "metadata": {},
   "source": [
    "# ì ì‘í˜• RAG (Adaptive RAG)\n",
    "\n",
    "ì ì‘í˜• RAGëŠ” (1) [ì§ˆì˜ ë¶„ì„](https://blog.langchain.dev/query-construction/)ê³¼ (2) [ëŠ¥ë™ì /ìê¸° ìˆ˜ì • RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)ë¥¼ ê²°í•©í•œ RAG ì „ëµì…ë‹ˆë‹¤.\n",
    "\n",
    "[ë…¼ë¬¸](https://arxiv.org/abs/2403.14403)ì—ì„œëŠ” ë‹¤ìŒ 3ê°€ì§€ ë°©ì‹ ê°„ ë¼ìš°íŒ…ì„ ìœ„í•œ ì§ˆì˜ ë¶„ì„ì„ ì œì‹œí•©ë‹ˆë‹¤:\n",
    "\n",
    "* ê²€ìƒ‰ ì—†ìŒ (No Retrieval) - ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ê²€ìƒ‰ ì—†ì´ ì§ì ‘ ë‹µë³€\n",
    "* ë‹¨ì¼ ë‹¨ê³„ RAG (Single-shot RAG) - ì¼ë°˜ì ì¸ RAG ë°©ì‹ìœ¼ë¡œ í•œ ë²ˆ ê²€ìƒ‰ í›„ ë‹µë³€\n",
    "* ë°˜ë³µì  RAG (Iterative RAG) - ë³µì¡í•œ ì§ˆë¬¸ì€ ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€ ê°œì„ \n",
    "\n",
    "ì´ë¥¼ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ì˜ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìŒ ë‘ ë°©ì‹ ê°„ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "* **ì›¹ ê²€ìƒ‰**: ìµœì‹  ì‚¬ê±´ê³¼ ê´€ë ¨ëœ ì§ˆì˜ìš© (ì‹¤ì‹œê°„ ì •ë³´ í•„ìš”)\n",
    "* **ìê¸° ìˆ˜ì • RAG**: ìš°ë¦¬ì˜ ì¸ë±ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆì˜ìš© (ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹)\n",
    "\n",
    "![Screenshot 2024-03-26 at 1.36.03 PM.png](attachment:36fa621a-9d3d-4860-a17c-5d20e6987481.png)\n",
    "\n",
    "## ğŸ” Adaptive RAG í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "**ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” 3-í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ:**\n",
    "- **í´ë˜ìŠ¤ A**: ê²€ìƒ‰ ì—†ì´ LLMë§Œìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ë‹¨ìˆœ ì§ˆë¬¸\n",
    "- **í´ë˜ìŠ¤ B**: ë‹¨ì¼ ê²€ìƒ‰ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì¼ë°˜ì  ì§ˆë¬¸  \n",
    "- **í´ë˜ìŠ¤ C**: ë‹¤ì¤‘ ê²€ìƒ‰ì´ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸\n",
    "\n",
    "**ë³¸ êµ¬í˜„ì˜ íŠ¹ì§•:**\n",
    "- T5-Large ë¶„ë¥˜ê¸° ëŒ€ì‹  GPT-4o-mini ì‚¬ìš©\n",
    "- í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ (ë¬¸ì„œ ê´€ë ¨ì„±, í™˜ê° ê²€ì¦, ë‹µë³€ í’ˆì§ˆ)\n",
    "- ìë™ ì§ˆì˜ ì¬ì‘ì„± ë° ì¬ê²€ìƒ‰ ë©”ì»¤ë‹ˆì¦˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85501ca-eb89-4795-aeab-cdab050ead6b",
   "metadata": {},
   "source": [
    "## ì„¤ì • (Setup)\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•„ìˆ˜ íŒ¨í‚¤ì§€ ëª©ë¡:**\n",
    "- `langchain_community`: ë‹¤ì–‘í•œ í†µí•© ë„êµ¬\n",
    "- `tiktoken`: OpenAI í† í¬ë‚˜ì´ì €\n",
    "- `langchain-openai`: OpenAI ëª¨ë¸ ì—°ë™\n",
    "- `chromadb`: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤\n",
    "- `langgraph`: ì›Œí¬í”Œë¡œ ê·¸ë˜í”„ ê´€ë¦¬\n",
    "- `tavily-python`: ì›¹ ê²€ìƒ‰ API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d1a740-9fea-4a6e-8f95-fb9dbf1c80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì¶œë ¥ ìˆ¨ê¹€)\n",
    "%%capture --no-stderr\n",
    "%pip install -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub chromadb langchain langgraph  tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f204d-956f-4128-b597-2c698120edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì • - í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ ë³´ì•ˆì  ì„¤ì •\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•¨ìˆ˜\n",
    "    \n",
    "    ì´ë¯¸ ì„¤ì •ëœ í™˜ê²½ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê³ ,\n",
    "    ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ìš”ì²­í•˜ì—¬ ì„¤ì •\n",
    "    \n",
    "    Args:\n",
    "        var: ì„¤ì •í•  í™˜ê²½ë³€ìˆ˜ëª…\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# í•„ìˆ˜ API í‚¤ ì„¤ì •\n",
    "_set_env(\"OPENAI_API_KEY\")     # OpenAI GPT ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ í‚¤\n",
    "# _set_env(\"COHERE_API_KEY\")   # Cohere ì„ë² ë”© ì‚¬ìš©ì‹œ í•„ìš” (ì„ íƒì‚¬í•­)\n",
    "_set_env(\"TAVILY_API_KEY\")     # ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•œ Tavily API í‚¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e04b18",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">LangGraph ê°œë°œì„ ìœ„í•œ <a href=\"https://smith.langchain.com\">LangSmith</a> ì„¤ì •</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        LangSmithì— ê°€ì…í•˜ì—¬ LangGraph í”„ë¡œì íŠ¸ì˜ ë¬¸ì œë¥¼ ì‹ ì†í•˜ê²Œ ë°œê²¬í•˜ê³  ì„±ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°ë¡œ LangGraphë¡œ êµ¬ì¶•í•œ LLM ì•±ì„ ë””ë²„ê·¸, í…ŒìŠ¤íŠ¸, ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€” ì‹œì‘ ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ <a href=\"https://docs.smith.langchain.com\">ì—¬ê¸°</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6",
   "metadata": {},
   "source": [
    "## ì¸ë±ìŠ¤ ìƒì„± (Create Index)\n",
    "\n",
    "OpenAI Embeddingsì™€ Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì¸ë±ì‹± ëŒ€ìƒ ë¬¸ì„œ:**\n",
    "- AI ì—ì´ì „íŠ¸ ê´€ë ¨ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸\n",
    "- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•\n",
    "- LLM ì ëŒ€ì  ê³µê²© ê¸°ë²•\n",
    "\n",
    "**ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ê³¼ì •:**\n",
    "1. ì›¹ ë¬¸ì„œ ë¡œë”©\n",
    "2. í† í° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í•  (chunk_size=500)\n",
    "3. OpenAI Embeddingsë¡œ ë²¡í„°í™”\n",
    "4. Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings  # Cohere ì„ë² ë”© ëŒ€ì•ˆ\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì • - OpenAI text-embedding-3-small ì‚¬ìš©\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "# ì¸ë±ì‹±í•  ë¬¸ì„œ URL ëª©ë¡\n",
    "# Lilian Wengì˜ ìœ ëª…í•œ AI/ML ì—°êµ¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë“¤\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",          # LLM ê¸°ë°˜ ììœ¨ ì—ì´ì „íŠ¸\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\", # í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",     # LLM ì ëŒ€ì  ê³µê²© ê¸°ë²•\n",
    "]\n",
    "\n",
    "# ì›¹ í˜ì´ì§€ ë¡œë”© - ê° URLì—ì„œ ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]  # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰íƒ„í™”\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "# tiktoken ê¸°ë°˜: OpenAIì˜ í† í¬ë‚˜ì´ì € ì‚¬ìš©ìœ¼ë¡œ ì •í™•í•œ í† í° ê³„ì‚°\n",
    "# chunk_size=500: ê° ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜\n",
    "# chunk_overlap=0: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì—†ìŒ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Chroma ë²¡í„°ìŠ¤í† ì–´ì— ë¬¸ì„œ ì¶”ê°€\n",
    "# collection_name: ë²¡í„° ì»¬ë ‰ì…˜ ì‹ë³„ì\n",
    "# embedding: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embd,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()  # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52b427-750c-40f8-8893-e9caab3afd8d",
   "metadata": {},
   "source": [
    "## LLM ëª¨ë¸ ì„¤ì •\n",
    "\n",
    "ì ì‘í˜• RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤:\n",
    "\n",
    "**ì£¼ìš” LLM ì—­í• :**\n",
    "1. **ë¼ìš°í„°**: ì§ˆì˜ë¥¼ ì›¹ê²€ìƒ‰/ë²¡í„°ìŠ¤í† ì–´ë¡œ ë¶„ê¸°\n",
    "2. **í‰ê°€ê¸°**: ë¬¸ì„œ ê´€ë ¨ì„±, í™˜ê°, ë‹µë³€ í’ˆì§ˆ ê²€ì¦\n",
    "3. **ìƒì„±ê¸°**: ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "4. **ì¬ì‘ì„±ê¸°**: ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ ì§ˆì˜ ê°œì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28baefd-a961-49b0-8394-c5478dadda1c",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">LangChainì—ì„œ Pydantic ì‚¬ìš©</p>\n",
    "    <p>\n",
    "        ì´ ë…¸íŠ¸ë¶ì€ Pydantic v2 <code>BaseModel</code>ì„ ì‚¬ìš©í•˜ë¯€ë¡œ <code>langchain-core >= 0.3</code>ì´ í•„ìš”í•©ë‹ˆë‹¤. <code>langchain-core < 0.3</code> ì‚¬ìš© ì‹œ Pydantic v1ê³¼ v2 <code>BaseModel</code>ì˜ í˜¼ì¬ë¡œ ì¸í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd5ac0-fa18-4ee9-8051-062a0c56268f",
   "metadata": {},
   "source": [
    "### ì§ˆì˜ ë¶„ì„ì„ ìœ„í•œ ë¼ìš°í„° (Router for Query Analysis)\n",
    "\n",
    "Adaptive RAGì˜ í•µì‹¬ì¸ **ì§€ëŠ¥í˜• ë¼ìš°íŒ…** ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë¼ìš°íŒ… ì „ëµ:**\n",
    "- **ë²¡í„°ìŠ¤í† ì–´ ë¼ìš°íŒ…**: ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹ (AI ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, ì ëŒ€ì  ê³µê²©)\n",
    "- **ì›¹ê²€ìƒ‰ ë¼ìš°íŒ…**: ì‹¤ì‹œê°„ ì •ë³´ í•„ìš” (ë‰´ìŠ¤, ìµœì‹  ì´ë²¤íŠ¸, ì‹œì¥ ë°ì´í„°)\n",
    "\n",
    "**ë…¼ë¬¸ vs êµ¬í˜„ ì°¨ì´ì :**\n",
    "- ë…¼ë¬¸: T5-Large ê¸°ë°˜ 3-í´ë˜ìŠ¤ ë¶„ë¥˜ê¸° (A/B/C)\n",
    "- ë³¸ êµ¬í˜„: GPT-4o-mini ê¸°ë°˜ 2-í´ë˜ìŠ¤ ë¼ìš°íŒ… (ë²¡í„°ìŠ¤í† ì–´/ì›¹ê²€ìƒ‰)\n",
    "\n",
    "**Pydantic êµ¬ì¡°í™”ëœ ì¶œë ¥**ì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ëœ ë¼ìš°íŒ… ê²°ì •ì„ ë³´ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë¼ìš°í„° êµ¬í˜„\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# ë¼ìš°íŒ… ê²°ì •ì„ ìœ„í•œ ë°ì´í„° ëª¨ë¸\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë°ì´í„°ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…\n",
    "    \n",
    "    Literal íƒ€ì…ìœ¼ë¡œ ê°€ëŠ¥í•œ ê°’ì„ ì œí•œí•˜ì—¬ \n",
    "    LLMì˜ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ê°•ì œ\n",
    "    \"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ì›¹ ê²€ìƒ‰ ë˜ëŠ” ë²¡í„°ìŠ¤í† ì–´ë¡œ ë¼ìš°íŒ…ì„ ì„ íƒ\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM ì„¤ì • - êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ temperature=0\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# ë¼ìš°íŒ… ê²°ì •ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "# ëª…í™•í•œ ê¸°ì¤€ì„ ì œì‹œí•˜ì—¬ ì¼ê´€ëœ ë¼ìš°íŒ… ê²°ì • ìœ ë„\n",
    "system = \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë²¡í„°ìŠ¤í† ì–´ ë˜ëŠ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë²¡í„°ìŠ¤í† ì–´ì—ëŠ” ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, ê·¸ë¦¬ê³  ì ëŒ€ì  ê³µê²©ì— ê´€ë ¨ëœ ë¬¸ì„œë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ì£¼ì œë“¤ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "### ë¼ìš°íŒ… íŒë‹¨ ê¸°ì¤€:\n",
    "\n",
    "**ë²¡í„°ìŠ¤í† ì–´ ì‚¬ìš© (vectorstore):**\n",
    "- AI ì—ì´ì „íŠ¸ ê´€ë ¨: ë©”ëª¨ë¦¬, ê³„íš, ë„êµ¬ ì‚¬ìš©, ë°˜ì„±, ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ\n",
    "- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§: few-shot, chain-of-thought, tree-of-thought, í”„ë¡¬í”„íŠ¸ ìµœì í™”\n",
    "- LLM ë³´ì•ˆ: ì ëŒ€ì  í”„ë¡¬í”„íŠ¸, jailbreaking, í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜, ë°©ì–´ ê¸°ë²•\n",
    "\n",
    "**ì›¹ê²€ìƒ‰ ì‚¬ìš© (web_search):**\n",
    "- ì‹¤ì‹œê°„/ìµœì‹  ì •ë³´: ë‰´ìŠ¤, í˜„ì¬ ì´ë²¤íŠ¸, ì£¼ì‹/ì•”í˜¸í™”í ê°€ê²©\n",
    "- ì‹œê°„ì— ë¯¼ê°í•œ ì •ë³´: ë‚ ì”¨, ìŠ¤í¬ì¸  ê²°ê³¼, ì •ì¹˜ ìƒí™©\n",
    "- ìœ„ ë„ë©”ì¸ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ë¼ìš°íŒ… ì²´ì¸ êµ¬ì„±: í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ êµ¬ì¡°í™”ëœ ì¶œë ¥\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "# ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸ - ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•ì— ëŒ€í•œ ë¼ìš°íŒ… ê²€ì¦\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"Who will the Bears draft first in the NFL draft?\"}  # ìµœì‹  ìŠ¤í¬ì¸  ì •ë³´ â†’ ì›¹ê²€ìƒ‰ ì˜ˆìƒ\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))  # AI ì—ì´ì „íŠ¸ â†’ ë²¡í„°ìŠ¤í† ì–´ ì˜ˆìƒ"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be-output",
   "metadata": {},
   "source": [
    "datasource='web_search'\n",
    "datasource='vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb248c94-0b0c-4d86-8565-32aa8d7424e4",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰ í‰ê°€ê¸° (Retrieval Grader)\n",
    "\n",
    "**í’ˆì§ˆ ë³´ì¥ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„**: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í‰ê°€ ê³¼ì •:**\n",
    "1. ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "2. ê° ë¬¸ì„œì™€ ì§ˆë¬¸ì˜ ê´€ë ¨ì„± í‰ê°€\n",
    "3. ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§\n",
    "4. ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë§Œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬\n",
    "\n",
    "**í‰ê°€ ê¸°ì¤€:**\n",
    "- í‚¤ì›Œë“œ ë§¤ì¹­: ì§ˆë¬¸ì˜ í•µì‹¬ ìš©ì–´ í¬í•¨\n",
    "- ì˜ë¯¸ì  ê´€ë ¨ì„±: ì§ˆë¬¸ì˜ ì˜ë„ì™€ ë¬¸ì„œ ë‚´ìš© ì¼ì¹˜\n",
    "- ì—„ê²©í•˜ì§€ ì•Šì€ í‰ê°€: ì˜ëª»ëœ ê²€ìƒ‰ ê²°ê³¼ ì œê±°ê°€ ëª©ì \n",
    "\n",
    "ì´ëŠ” Adaptive RAG ë…¼ë¬¸ì˜ **í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ**ì„ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856801cb-f42a-44e7-956f-47845e3664ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê²€ìƒ‰ í‰ê°€ê¸°\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„± ê²€ì‚¬ë¥¼ ìœ„í•œ ì´ì§„ í‰ì \n",
    "    \n",
    "    ì´ì§„ ë¶„ë¥˜ë¡œ ë‹¨ìˆœí™”í•˜ì—¬ LLMì˜ ì¼ê´€ëœ íŒë‹¨ ìœ ë„\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©´ 'yes', ì—†ìœ¼ë©´ 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í‰ê°€ìš© LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "# ê´€ëŒ€í•œ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì • - ì™„ì „íˆ ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œë§Œ í•„í„°ë§\n",
    "system = \"\"\"ë‹¹ì‹ ì€ ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ëŠ” í‰ê°€ìì…ë‹ˆë‹¤. \\n \n",
    "    ë¬¸ì„œê°€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œë‚˜ ì˜ë¯¸ì  ë‚´ìš©ì„ í¬í•¨í•˜ê³  ìˆë‹¤ë©´ ê´€ë ¨ì´ ìˆë‹¤ê³  í‰ê°€í•˜ì„¸ìš”. \\n\n",
    "    ì—„ê²©í•œ í…ŒìŠ¤íŠ¸ì¼ í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. ëª©í‘œëŠ” ì˜ëª»ëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê±¸ëŸ¬ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤. \\n\n",
    "    ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ì§„ ì ìˆ˜ 'yes' ë˜ëŠ” 'no'ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "    \n",
    "    ### í‰ê°€ ê°€ì´ë“œë¼ì¸:\n",
    "    \n",
    "    **'yes' ì¡°ê±´ (ê´€ë ¨ ìˆìŒ):**\n",
    "    - ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ê°œë…ì´ ë¬¸ì„œì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë¨\n",
    "    - ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì´ë‚˜ ë§¥ë½ í¬í•¨\n",
    "    - ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì •ë³´ ì¡´ì¬\n",
    "    - ë™ì˜ì–´ë‚˜ ê´€ë ¨ ìš©ì–´ë¥¼ í†µí•œ ê°„ì ‘ì  ì—°ê´€ì„±\n",
    "    \n",
    "    **'no' ì¡°ê±´ (ê´€ë ¨ ì—†ìŒ):**\n",
    "    - ì§ˆë¬¸ê³¼ ì™„ì „íˆ ë‹¤ë¥¸ ì£¼ì œë‚˜ ë„ë©”ì¸\n",
    "    - í‚¤ì›Œë“œëŠ” ìˆì§€ë§Œ ì™„ì „íˆ ë‹¤ë¥¸ ë§¥ë½ì—ì„œ ì‚¬ìš©ë¨\n",
    "    - ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° ì „í˜€ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ë‚´ìš©\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"ê²€ìƒ‰ëœ ë¬¸ì„œ: \\n\\n {document} \\n\\n ì‚¬ìš©ì ì§ˆë¬¸: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ í‰ê°€ ì²´ì¸ êµ¬ì„±\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# í‰ê°€ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰\n",
    "question = \"agent memory\"  # AI ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ì— ê´€í•œ ì§ˆë¬¸\n",
    "docs = retriever.invoke(question)  # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "doc_txt = docs[1].page_content  # ë‘ ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "856801cb-f42a-44e7-956f-47845e3664ca-output",
   "metadata": {},
   "source": [
    "binary_score='yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "source": [
    "### ìƒì„± (Generate)\n",
    "\n",
    "**RAGì˜ í•µì‹¬**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ìƒì„± ê³¼ì •:**\n",
    "1. ê´€ë ¨ì„±ì´ ê²€ì¦ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "2. LangChain Hubì˜ ê²€ì¦ëœ RAG í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "3. GPT-4o-minië¡œ ë‹µë³€ ìƒì„±\n",
    "4. ë¬¸ìì—´ íŒŒì„œë¡œ ìµœì¢… í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "\n",
    "**í”„ë¡¬í”„íŠ¸ ìµœì í™”:**\n",
    "- `rlm/rag-prompt`: ì»¤ë®¤ë‹ˆí‹° ê²€ì¦ëœ RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "- ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ íš¨ê³¼ì ìœ¼ë¡œ êµ¬ì¡°í™”\n",
    "- í™˜ê° ìµœì†Œí™”ë¥¼ ìœ„í•œ ì§€ì‹œì‚¬í•­ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ìƒì„±\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain Hubì—ì„œ ê²€ì¦ëœ RAG í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "# ì´ í”„ë¡¬í”„íŠ¸ëŠ” ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ë°›ì•„ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ìµœì í™”ë¨\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# ë‹µë³€ ìƒì„±ìš© LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    \n",
    "    ê° ë¬¸ì„œë¥¼ ë‘ ì¤„ ê°„ê²©(\\n\\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬\n",
    "    LLMì´ ì„œë¡œ ë‹¤ë¥¸ ë¬¸ì„œì„ì„ ì¸ì‹í•˜ë„ë¡ í•¨\n",
    "    \n",
    "    Args:\n",
    "        docs: Document ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        \n",
    "    Returns:\n",
    "        str: ê²°í•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±: í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ë¬¸ìì—´ íŒŒì„œ\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ì‹¤í–‰\n",
    "docs_txt = format_docs(docs)  # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8-output",
   "metadata": {},
   "source": [
    "Agent memory in LLM-powered autonomous systems consists of short-term and long-term memory. Short-term memory utilizes in-context learning for immediate tasks, while long-term memory allows agents to retain and recall information over extended periods, often using external storage for efficient retrieval. This memory structure supports the agent's ability to reflect on past actions and improve future performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ab54a-4a4f-45fa-b1c5-cea1bf4c59d5",
   "metadata": {},
   "source": [
    "### í™˜ê° í‰ê°€ê¸° (Hallucination Grader)\n",
    "\n",
    "**í’ˆì§ˆ ë³´ì¥ì˜ ë‘ ë²ˆì§¸ ë‹¨ê³„**: ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì‚¬ì‹¤ì— ê·¼ê±°í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í™˜ê° ê²€ì¦ ê³¼ì •:**\n",
    "1. ìƒì„±ëœ ë‹µë³€ì˜ ëª¨ë“  ì£¼ì¥ ë¶„ì„\n",
    "2. ê° ì£¼ì¥ì´ ì œê³µëœ ë¬¸ì„œì—ì„œ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ í™•ì¸\n",
    "3. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ ì¶”ê°€ ì—¬ë¶€ ê²€ì‚¬\n",
    "4. ì‚¬ì‹¤ ì™œê³¡ì´ë‚˜ ì˜ëª»ëœ í•´ì„ ê²€ì¶œ\n",
    "\n",
    "**í™˜ê°ì˜ ìœ í˜•:**\n",
    "- **ì •ë³´ ë¶€ì¡± í™˜ê°**: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš© ìƒì„±\n",
    "- **í•´ì„ ì˜¤ë¥˜**: ë¬¸ì„œ ë‚´ìš©ì˜ ì˜ëª»ëœ í•´ì„\n",
    "- **ê³¼ë„í•œ ì¼ë°˜í™”**: ì œí•œì  ì •ë³´ì˜ í™•ëŒ€ í•´ì„\n",
    "\n",
    "ì´ëŠ” **Self-Corrective RAG**ì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### í™˜ê° í‰ê°€ê¸°\n",
    "\n",
    "\n",
    "# í™˜ê° ê²€ì¶œì„ ìœ„í•œ ë°ì´í„° ëª¨ë¸\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ë‹µë³€ì˜ í™˜ê° ì—¬ë¶€ ê²€ì‚¬\n",
    "    \n",
    "    í™˜ê°: ì œê³µëœ ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•Šì€ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” í˜„ìƒ\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"ë‹µë³€ì´ ì‚¬ì‹¤ì— ê·¼ê±°í•˜ê³  ìˆìœ¼ë©´ 'yes', í™˜ê°ì´ ìˆìœ¼ë©´ 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# í™˜ê° í‰ê°€ìš© LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# í™˜ê° ê²€ì¦ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "# ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ í™˜ê° ê²€ì¶œ - ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ í—ˆìš©\n",
    "system = \"\"\"ë‹¹ì‹ ì€ LLMì˜ ìƒì„± ê²°ê³¼ê°€ ê²€ìƒ‰ëœ ì‚¬ì‹¤ë“¤ì— ê·¼ê±°í•˜ëŠ”ì§€/ì§€ì›ë˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” í‰ê°€ìì…ë‹ˆë‹¤. \\n \n",
    "     ì´ì§„ ì ìˆ˜ 'yes' ë˜ëŠ” 'no'ë¥¼ ì œê³µí•˜ì„¸ìš”. 'Yes'ëŠ” ë‹µë³€ì´ ì‚¬ì‹¤ë“¤ì— ê·¼ê±°í•˜ê³  ìˆìŒ/ì§€ì›ë˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "     \n",
    "     ### í™˜ê° ê²€ì¶œ ê¸°ì¤€:\n",
    "     \n",
    "     **'yes' ì¡°ê±´ (ì‚¬ì‹¤ ê·¼ê±°):**\n",
    "     - ìƒì„±ëœ ë‹µë³€ì˜ ëª¨ë“  ì£¼ì¥ì´ ì œê³µëœ ë¬¸ì„œì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥\n",
    "     - ë¬¸ì„œì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ê³  í•´ì„\n",
    "     - ì¶”ë¡ ì´ ìˆë”ë¼ë„ ë¬¸ì„œ ë‚´ìš©ì— ë…¼ë¦¬ì ìœ¼ë¡œ ê¸°ë°˜\n",
    "     - ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì ì ˆíˆ í•œì •ì  í‘œí˜„ ì‚¬ìš©\n",
    "     \n",
    "     **'no' ì¡°ê±´ (í™˜ê° ì¡´ì¬):**\n",
    "     - ë¬¸ì„œì— ì „í˜€ ì–¸ê¸‰ë˜ì§€ ì•Šì€ êµ¬ì²´ì  ì‚¬ì‹¤ì´ë‚˜ ìˆ˜ì¹˜ í¬í•¨\n",
    "     - ë¬¸ì„œì˜ ë‚´ìš©ì„ ëª…ë°±íˆ ì˜ëª» í•´ì„í•˜ê±°ë‚˜ ì™œê³¡\n",
    "     - ë¬¸ì„œì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ í™•ì •ì  ì£¼ì¥\n",
    "     - ìƒì‹ì  ì§€ì‹ì´ë¼ë„ ë¬¸ì„œì™€ ëª¨ìˆœë˜ëŠ” ë‚´ìš©\"\"\"\n",
    "     \n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"ì‚¬ì‹¤ ì§‘í•©: \\n\\n {documents} \\n\\n LLM ìƒì„± ê²°ê³¼: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í™˜ê° í‰ê°€ ì²´ì¸ êµ¬ì„±\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "# í™˜ê° ê²€ì¦ í…ŒìŠ¤íŠ¸\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3-output",
   "metadata": {},
   "source": [
    "GradeHallucinations(binary_score='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58502a-c25f-4d80-a402-5583b0cd3e41",
   "metadata": {},
   "source": [
    "### ë‹µë³€ í‰ê°€ê¸° (Answer Grader)\n",
    "\n",
    "**í’ˆì§ˆ ë³´ì¥ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„**: ìƒì„±ëœ ë‹µë³€ì´ ì›ë˜ ì§ˆë¬¸ì„ ì ì ˆíˆ í•´ê²°í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë‹µë³€ í’ˆì§ˆ í‰ê°€ ê¸°ì¤€:**\n",
    "1. **ì™„ì „ì„±**: ì§ˆë¬¸ì˜ ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ë£¸\n",
    "2. **ì •í™•ì„±**: ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì´í•´\n",
    "3. **ê´€ë ¨ì„±**: ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‹µë³€\n",
    "4. **ëª…í™•ì„±**: ì´í•´í•˜ê¸° ì‰½ê³  êµ¬ì²´ì ì¸ ë‹µë³€\n",
    "\n",
    "**í‰ê°€ ê³¼ì •:**\n",
    "- ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ íŒŒì•…\n",
    "- ë‹µë³€ì˜ ì¶©ì‹¤ë„ ê²€ì‚¬\n",
    "- ì¶”ê°€ ì •ë³´ í•„ìš”ì„± íŒë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded99680-437a-4c9d-b860-619c88949d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë‹µë³€ í‰ê°€ê¸°\n",
    "\n",
    "\n",
    "# ë‹µë³€ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ”ì§€ í‰ê°€\n",
    "    \n",
    "    í™˜ê° ê²€ì¦ê³¼ëŠ” ë³„ê°œë¡œ, ë‹µë³€ì˜ ì‹¤ì œ ìœ ìš©ì„±ì„ í‰ê°€\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ë©´ 'yes', í•´ê²°í•˜ì§€ ëª»í•˜ë©´ 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ë‹µë³€ í‰ê°€ìš© LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# ë‹µë³€ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "# ì‚¬ìš©ì ê´€ì ì—ì„œì˜ ë‹µë³€ ìœ ìš©ì„± í‰ê°€\n",
    "system = \"\"\"ë‹¹ì‹ ì€ ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ”ì§€/í•´ê²°í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” í‰ê°€ìì…ë‹ˆë‹¤ \\n \n",
    "     ì´ì§„ ì ìˆ˜ 'yes' ë˜ëŠ” 'no'ë¥¼ ì œê³µí•˜ì„¸ìš”. 'Yes'ëŠ” ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "     \n",
    "     ### ë‹µë³€ í’ˆì§ˆ í‰ê°€ ê¸°ì¤€:\n",
    "     \n",
    "     **'yes' ì¡°ê±´ (ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€):**\n",
    "     - ì§ˆë¬¸ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ì˜ë„ë¥¼ ì •í™•íˆ ë‹¤ë£¸\n",
    "     - ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” êµ¬ì²´ì  ì •ë³´ë‚˜ ì„¤ëª… ì œê³µ\n",
    "     - ì§ˆë¬¸ì˜ ë§¥ë½ê³¼ ìˆ˜ì¤€ì— ì í•©í•œ ë‹µë³€\n",
    "     - ì™„ì „í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€\n",
    "     - ì§ˆë¬¸ìê°€ ì›í•˜ëŠ” ë°”ë¥¼ ì¶©ì¡±\n",
    "     \n",
    "     **'no' ì¡°ê±´ (ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€):**\n",
    "     - ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ êµ¬ì„±\n",
    "     - ì§ˆë¬¸ì˜ í•µì‹¬ì„ ë†“ì¹˜ê±°ë‚˜ í”¼í•´ê°„ ë‹µë³€\n",
    "     - ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ëª¨í˜¸í•œ ë‹µë³€\n",
    "     - ë¶ˆì™„ì „í•˜ì—¬ ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•œ ë‹µë³€\n",
    "     - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì™„ì „íˆ ì˜¤í•´í•œ ë‹µë³€\"\"\"\n",
    "     \n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"ì‚¬ìš©ì ì§ˆë¬¸: \\n\\n {question} \\n\\n LLM ìƒì„± ê²°ê³¼: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ë‹µë³€ í‰ê°€ ì²´ì¸ êµ¬ì„±\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "\n",
    "# ë‹µë³€ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ded99680-437a-4c9d-b860-619c88949d84-output",
   "metadata": {},
   "source": [
    "GradeAnswer(binary_score='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77946c-2646-4039-86b0-e2fde1ab7459",
   "metadata": {},
   "source": [
    "### ì§ˆì˜ ì¬ì‘ì„± (Question Rewriting)\n",
    "\n",
    "**ìê¸° ìˆ˜ì • ë©”ì»¤ë‹ˆì¦˜**: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•˜ì—¬ ë” ë‚˜ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì¬ì‘ì„±ì´ í•„ìš”í•œ ê²½ìš°:**\n",
    "1. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°\n",
    "2. ë‹µë³€ í’ˆì§ˆì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì€ ê²½ìš°\n",
    "3. í™˜ê°ì´ ê²€ì¶œëœ ê²½ìš°\n",
    "\n",
    "**ì¬ì‘ì„± ì „ëµ:**\n",
    "- **í‚¤ì›Œë“œ ìµœì í™”**: ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ í•µì‹¬ ìš©ì–´ ì¶”ê°€\n",
    "- **ì˜ë¯¸ ëª…í™•í™”**: ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì ìœ¼ë¡œ ë³€í™˜\n",
    "- **ê²€ìƒ‰ ì¹œí™”ì  í˜•íƒœ**: ë²¡í„° ìœ ì‚¬ì„± ê²€ìƒ‰ì— ì í•©í•œ êµ¬ì¡°\n",
    "- **ë„ë©”ì¸ ìš©ì–´**: ì „ë¬¸ ë¶„ì•¼ ìš©ì–´ë¡œ ì •í™•ì„± í–¥ìƒ\n",
    "\n",
    "**ì˜ˆì‹œ ë³€í™˜:**\n",
    "- \"ë©”ëª¨ë¦¬ê°€ ë­ì•¼?\" â†’ \"AI ì—ì´ì „íŠ¸ì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œê³¼ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?\"\n",
    "- \"ì–´ë–»ê²Œ í•´?\" â†’ \"í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì—ì„œ few-shot learningì„ ì–´ë–»ê²Œ êµ¬í˜„í•˜ëŠ”ê°€?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì§ˆì˜ ì¬ì‘ì„±ê¸°\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„±ìš© LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "# ë²¡í„° ê²€ìƒ‰ ìµœì í™”ì— íŠ¹í™”ëœ ì¬ì‘ì„± ì§€ì¹¨\n",
    "system = \"\"\"ë‹¹ì‹ ì€ ì…ë ¥ ì§ˆë¬¸ì„ ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ì— ìµœì í™”ëœ ë” ë‚˜ì€ ë²„ì „ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì§ˆë¬¸ ì¬ì‘ì„±ê¸°ì…ë‹ˆë‹¤. \\n \n",
    "     ì…ë ¥ì„ ë³´ê³  ê·¸ ê·¼ë³¸ì ì¸ ì˜ë¯¸ì  ì˜ë„/ì˜ë¯¸ì— ëŒ€í•´ ì¶”ë¡ í•´ë³´ì„¸ìš”.\n",
    "     \n",
    "     ### ì¬ì‘ì„± ìµœì í™” ì›ì¹™:\n",
    "     \n",
    "     **1. í‚¤ì›Œë“œ ê°•í™”:**\n",
    "     - ê²€ìƒ‰ì— ì¤‘ìš”í•œ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ í¬í•¨\n",
    "     - ë™ì˜ì–´ì™€ ê´€ë ¨ ìš©ì–´ í™œìš©\n",
    "     - êµ¬ì²´ì ì´ê³  ê¸°ìˆ ì ì¸ ìš©ì–´ ì„ í˜¸\n",
    "     \n",
    "     **2. êµ¬ì¡°ì  ëª…í™•í™”:**\n",
    "     - ëª¨í˜¸í•œ ëŒ€ëª…ì‚¬ë‚˜ ì§€ì‹œì–´ ì œê±°\n",
    "     - ì™„ì „í•œ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš©\n",
    "     - ê²€ìƒ‰ ì˜ë„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„\n",
    "     \n",
    "     **3. ë§¥ë½ ë³´ê°•:**\n",
    "     - í•„ìš”ì‹œ ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€\n",
    "     - ì§ˆë¬¸ì˜ ë²”ìœ„ì™€ ê¹Šì´ ëª…í™•í™”\n",
    "     - ê¸°ìˆ ì  ìˆ˜ì¤€ ëª…ì‹œ\n",
    "     \n",
    "     **4. ê²€ìƒ‰ ì¹œí™”ì„±:**\n",
    "     - ë²¡í„° ì„ë² ë”©ì— ìœ ë¦¬í•œ í‘œí˜„ ì‚¬ìš©\n",
    "     - ì˜ë¯¸ì  ë°€ë„ ë†’ì€ êµ¬ë¬¸ êµ¬ì„±\n",
    "     - ê²€ìƒ‰ ê°€ëŠ¥í•œ ê°œë…ë“¤ë¡œ ë¶„í•´\n",
    "     \n",
    "     ### ë„ë©”ì¸ë³„ ì¬ì‘ì„± ì˜ˆì‹œ:\n",
    "     \n",
    "     **AI ì—ì´ì „íŠ¸:**\n",
    "     - \"ë©”ëª¨ë¦¬\" â†’ \"AI ì—ì´ì „íŠ¸ì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬ ë©”ì»¤ë‹ˆì¦˜\"\n",
    "     - \"ê³„íš\" â†’ \"AI ì—ì´ì „íŠ¸ì˜ ê³„íš ìˆ˜ë¦½ ì•Œê³ ë¦¬ì¦˜ê³¼ ëª©í‘œ ë¶„í•´ ì „ëµ\"\n",
    "     \n",
    "     **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§:**\n",
    "     - \"ì¢‹ì€ í”„ë¡¬í”„íŠ¸\" â†’ \"íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ì›ì¹™ê³¼ few-shot learning ê¸°ë²•\"\n",
    "     - \"ê°œì„  ë°©ë²•\" â†’ \"í”„ë¡¬í”„íŠ¸ ìµœì í™” ê¸°ë²•ê³¼ ì„±ëŠ¥ í–¥ìƒ ì „ëµ\"\n",
    "     \n",
    "     **ë³´ì•ˆ:**\n",
    "     - \"ê³µê²©\" â†’ \"LLM ì ëŒ€ì  í”„ë¡¬í”„íŠ¸ ê³µê²© ê¸°ë²•ê³¼ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜\"\n",
    "     - \"ì•ˆì „ì„±\" â†’ \"í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì§€ ë° ë³´ì•ˆ ê°•í™” ë°©ì•ˆ\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"ë‹¤ìŒì€ ì´ˆê¸° ì§ˆë¬¸ì…ë‹ˆë‹¤: \\n\\n {question} \\n ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ ê°œì„ ëœ ì§ˆë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„± ì²´ì¸ êµ¬ì„±\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„± í…ŒìŠ¤íŠ¸\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e-output",
   "metadata": {},
   "source": [
    "'What are the key concepts and techniques related to agent memory in artificial intelligence?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c0b31-b919-4498-869f-9673125c2473",
   "metadata": {},
   "source": [
    "## ì›¹ ê²€ìƒ‰ ë„êµ¬ (Web Search Tool)\n",
    "\n",
    "**ì‹¤ì‹œê°„ ì •ë³´ íšë“**: Tavily Search APIë¥¼ í†µí•œ ìµœì‹  ì •ë³´ ê²€ìƒ‰\n",
    "\n",
    "**Tavily ì„ íƒ ì´ìœ :**\n",
    "- LLM ì¹œí™”ì  ê²€ìƒ‰ ê²°ê³¼ ì œê³µ\n",
    "- êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜\n",
    "- ë†’ì€ í’ˆì§ˆì˜ ì½˜í…ì¸  í•„í„°ë§\n",
    "- API ê¸°ë°˜ ì•ˆì •ì  ì„œë¹„ìŠ¤\n",
    "\n",
    "**ê²€ìƒ‰ ì„¤ì •:**\n",
    "- `k=3`: ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ë°˜í™˜ (ê´€ë ¨ì„±ê³¼ íš¨ìœ¨ì„± ê· í˜•)\n",
    "- ìë™ ì½˜í…ì¸  ì •ì œ ë° ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d829bb-1074-4976-b650-ead41dcb9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê²€ìƒ‰\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "# k=3: ìµœìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜\n",
    "# í† í° ì‚¬ìš©ëŸ‰ê³¼ ì •ë³´ í’ˆì§ˆì˜ ìµœì  ê· í˜•ì \n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ êµ¬ì„± (Construct the Graph)\n",
    "\n",
    "**LangGraphë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œ ì„¤ê³„**: ë³µì¡í•œ RAG ì‹œìŠ¤í…œì„ ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ë¡œ êµ¬í˜„\n",
    "\n",
    "**ê·¸ë˜í”„ ì„¤ê³„ ì² í•™:**\n",
    "- **ìƒíƒœ ì¤‘ì‹¬**: ëª¨ë“  ì •ë³´ë¥¼ ê·¸ë˜í”„ ìƒíƒœë¡œ ê´€ë¦¬\n",
    "- **ì¡°ê±´ë¶€ ë¶„ê¸°**: ë™ì  ì›Œí¬í”Œë¡œ ê²½ë¡œ ê²°ì •\n",
    "- **ìê¸° ìˆ˜ì •**: í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„\n",
    "- **ëª¨ë“ˆí™”**: ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ì¸ ë…¸ë“œë¡œ ë¶„ë¦¬\n",
    "\n",
    "### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜ (Define Graph State)\n",
    "\n",
    "**StateGraphì˜ í•µì‹¬**: ëª¨ë“  ë…¸ë“œê°€ ê³µìœ í•˜ëŠ” ë°ì´í„° êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723fcdb-06e6-402d-912e-899795b78408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Adaptive RAG ê·¸ë˜í”„ì˜ ì „ì—­ ìƒíƒœ ì •ì˜\n",
    "    \n",
    "    TypedDictë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ì… ì•ˆì „ì„± ë³´ì¥\n",
    "    ëª¨ë“  ë…¸ë“œê°€ ì´ ìƒíƒœë¥¼ ê³µìœ í•˜ê³  ìˆ˜ì • ê°€ëŠ¥\n",
    "\n",
    "    Attributes:\n",
    "        question: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‚¬ìš©ì ì§ˆë¬¸ (ì›ë³¸ ë˜ëŠ” ì¬ì‘ì„±ë¨)\n",
    "        generation: LLMì´ ìƒì„±í•œ ìµœì¢… ë‹µë³€\n",
    "        documents: ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    question: str          # ì‚¬ìš©ì ì§ˆë¬¸ - ì¬ì‘ì„±ë  ìˆ˜ ìˆìŒ\n",
    "    generation: str        # ìƒì„±ëœ ë‹µë³€ - ì¬ìƒì„±ë  ìˆ˜ ìˆìŒ\n",
    "    documents: List[str]   # ê²€ìƒ‰ ë¬¸ì„œ - í•„í„°ë§ë  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d6c0d-42e8-4399-9751-e315be16607a",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ í”Œë¡œìš° ì •ì˜ (Define Graph Flow)\n",
    "\n",
    "**ë…¸ë“œ í•¨ìˆ˜ ì„¤ê³„**: ê° ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë…ë¦½ì ì¸ í•¨ìˆ˜ë¡œ êµ¬í˜„\n",
    "\n",
    "**ì„¤ê³„ ì›ì¹™:**\n",
    "- **ìˆœìˆ˜ í•¨ìˆ˜**: ë¶€ì‘ìš© ì—†ëŠ” ìƒíƒœ ë³€í™˜\n",
    "- **ëª…í™•í•œ ì…ì¶œë ¥**: ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ì…ë ¥/ì¶œë ¥\n",
    "- **ë¡œê¹…**: ê° ë‹¨ê³„ì˜ ì‹¤í–‰ ìƒíƒœ ì¶œë ¥\n",
    "- **ì˜¤ë¥˜ ì²˜ë¦¬**: ì˜ˆì™¸ ìƒí™© ëŒ€ì‘\n",
    "\n",
    "**ë…¸ë“œ ìœ í˜•:**\n",
    "1. **ì²˜ë¦¬ ë…¸ë“œ**: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰ (retrieve, generate, etc.)\n",
    "2. **í‰ê°€ ë…¸ë“œ**: í’ˆì§ˆ ê²€ì¦ (grade_documents)\n",
    "3. **ë³€í™˜ ë…¸ë“œ**: ë°ì´í„° ë³€í™˜ (transform_query)\n",
    "4. **ë¶„ê¸° í•¨ìˆ˜**: ì¡°ê±´ë¶€ ë¼ìš°íŒ… (route_question, decide_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ==================== í•µì‹¬ ì²˜ë¦¬ ë…¸ë“œë“¤ ====================\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    \n",
    "    ê²€ìƒ‰ ê³¼ì •:\n",
    "    1. í˜„ì¬ ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "    2. ë²¡í„° ìœ ì‚¬ì„± ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    3. ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜ (ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): documents í‚¤ì— ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    \n",
    "    ìƒì„± ê³¼ì •:\n",
    "    1. ë¬¸ì„œë“¤ì„ ë‹¨ì¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "    2. RAG í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ ì…ë ¥\n",
    "    3. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    4. í›„ì²˜ë¦¬ ë° ì •ì œ\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): generation í‚¤ì— ìƒì„±ëœ ë‹µë³€ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG ë°©ì‹ ë‹µë³€ ìƒì„±\n",
    "    docs_txt = format_docs(documents)\n",
    "    generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì§ˆë¬¸ ê´€ë ¨ì„± í‰ê°€ ë° í•„í„°ë§\n",
    "    \n",
    "    í’ˆì§ˆ ë³´ì¥ ê³¼ì •:\n",
    "    1. ê° ë¬¸ì„œë³„ë¡œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
    "    2. ì„ê³„ê°’ ê¸°ì¤€ ê´€ë ¨ ë¬¸ì„œë§Œ ì„ ë³„\n",
    "    3. í•„í„°ë§ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    4. í†µê³„ ì •ë³´ ë¡œê¹…\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): í•„í„°ë§ëœ ë¬¸ì„œë¡œ documents í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ê° ë¬¸ì„œë³„ ê´€ë ¨ì„± í‰ê°€\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì§ˆì˜ ì¬ì‘ì„±\n",
    "    \n",
    "    ì¬ì‘ì„± ì „ëµ:\n",
    "    1. ì›ë³¸ ì§ˆë¬¸ì˜ ì˜ë„ ë¶„ì„\n",
    "    2. ê²€ìƒ‰ ì¹œí™”ì  í‚¤ì›Œë“œ ì¶”ê°€\n",
    "    3. ëª¨í˜¸í•œ í‘œí˜„ ëª…í™•í™”\n",
    "    4. ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì ìš©\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): ì¬ì‘ì„±ëœ ì§ˆë¬¸ìœ¼ë¡œ question í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ì§ˆì˜ ì¬ì‘ì„± ì‹¤í–‰\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Tavily APIë¥¼ í†µí•œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    \n",
    "    ì›¹ ê²€ìƒ‰ ê³¼ì •:\n",
    "    1. ì§ˆë¬¸ì„ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜\n",
    "    2. Tavily API í˜¸ì¶œ\n",
    "    3. ê²€ìƒ‰ ê²°ê³¼ ì •ì œ ë° êµ¬ì¡°í™”\n",
    "    4. Document ê°ì²´ë¡œ ë³€í™˜\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¡œ documents í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Tavily ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¨ì¼ ë¬¸ì„œë¡œ ê²°í•©\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "    return {\"documents\": web_results, \"question\": question}\n",
    "\n",
    "\n",
    "# ==================== ì¡°ê±´ë¶€ ë¶„ê¸° í•¨ìˆ˜ë“¤ ====================\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ ë˜ëŠ” RAGë¡œ ë¼ìš°íŒ…\n",
    "    \n",
    "    ë¼ìš°íŒ… ë¡œì§:\n",
    "    1. ì§ˆë¬¸ì„ ë¼ìš°í„° LLMì— ì…ë ¥\n",
    "    2. êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ë¼ìš°íŒ… ê²°ì • ë°›ìŒ\n",
    "    3. ê²°ì •ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ì§€ì •\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ (\"web_search\" ë˜ëŠ” \"vectorstore\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •\n",
    "    \n",
    "    ê²°ì • ë¡œì§:\n",
    "    - ê´€ë ¨ ë¬¸ì„œ ì¡´ì¬: ë‹µë³€ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰\n",
    "    - ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ: ì§ˆì˜ ì¬ì‘ì„± í›„ ì¬ê²€ìƒ‰\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ (\"generate\" ë˜ëŠ” \"transform_query\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ê²€ì‚¬ì—ì„œ í•„í„°ë§ë¨\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # ê´€ë ¨ ë¬¸ì„œ ì¡´ì¬, ë‹µë³€ ìƒì„± ì§„í–‰\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆ ì¢…í•© í‰ê°€\n",
    "    \n",
    "    2ë‹¨ê³„ í’ˆì§ˆ ê²€ì¦:\n",
    "    1. í™˜ê° ê²€ì¦: ë‹µë³€ì´ ë¬¸ì„œì— ê·¼ê±°í•˜ëŠ”ê°€?\n",
    "    2. ë‹µë³€ í’ˆì§ˆ: ì§ˆë¬¸ì„ ì ì ˆíˆ í•´ê²°í•˜ëŠ”ê°€?\n",
    "    \n",
    "    ì¢…í•© íŒì •:\n",
    "    - ë‘ ê²€ì¦ ëª¨ë‘ í†µê³¼: ì„±ê³µì  ì™„ë£Œ\n",
    "    - í™˜ê° ê²€ì¶œ: ì¬ìƒì„± í•„ìš”\n",
    "    - ë‹µë³€ ë¶€ì¡±: ì§ˆì˜ ì¬ì‘ì„± í›„ ì¬ì‹œë„\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: ë‹¤ìŒ í–‰ë™ (\"useful\", \"not supported\", \"not useful\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 1ë‹¨ê³„: í™˜ê° ê²€ì¦\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë‹µë³€ í’ˆì§ˆ ê²€ì¦\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì»´íŒŒì¼ (Compile Graph)\n",
    "\n",
    "**ì›Œí¬í”Œë¡œ êµ¬ì„±**: ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì—°ê²°í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ê·¸ë˜í”„ ìƒì„±\n",
    "\n",
    "**ê·¸ë˜í”„ êµ¬ì¡°:**\n",
    "```\n",
    "START â†’ route_question\n",
    "â”œâ”€â”€ web_search â†’ generate â†’ quality_check â†’ END\n",
    "â””â”€â”€ vectorstore â†’ retrieve â†’ grade_docs â†’ decide\n",
    "    â”œâ”€â”€ transform_query â†’ retrieve (ì¬ì‹œë„)\n",
    "    â””â”€â”€ generate â†’ quality_check\n",
    "        â”œâ”€â”€ useful â†’ END\n",
    "        â”œâ”€â”€ not_useful â†’ transform_query\n",
    "        â””â”€â”€ not_supported â†’ generate\n",
    "```\n",
    "\n",
    "**ì—£ì§€ ìœ í˜•:**\n",
    "1. **ê³ ì • ì—£ì§€**: í•­ìƒ ê°™ì€ ë…¸ë“œë¡œ ì´ë™\n",
    "2. **ì¡°ê±´ë¶€ ì—£ì§€**: ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ë¶„ê¸°\n",
    "3. **ë£¨í”„ ì—£ì§€**: í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì¬ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# StateGraph ì¸ìŠ¤í„´ìŠ¤ ìƒì„± - GraphState íƒ€ì… ì‚¬ìš©\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ==================== ë…¸ë“œ ë“±ë¡ ====================\n",
    "# ê° ë…¸ë“œëŠ” íŠ¹ì • ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜ì™€ ë§¤í•‘\n",
    "\n",
    "workflow.add_node(\"web_search\", web_search)           # ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n",
    "workflow.add_node(\"retrieve\", retrieve)               # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ë…¸ë“œ\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "workflow.add_node(\"generate\", generate)               # ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "workflow.add_node(\"transform_query\", transform_query) # ì§ˆì˜ ì¬ì‘ì„± ë…¸ë“œ\n",
    "\n",
    "# ==================== ì—£ì§€ êµ¬ì„± ====================\n",
    "\n",
    "# ì‹œì‘ì ì—ì„œ ë¼ìš°íŒ… ê²°ì •\n",
    "workflow.add_conditional_edges(\n",
    "    START,           # ì‹œì‘ ë…¸ë“œ\n",
    "    route_question,  # ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "    {\n",
    "        \"web_search\": \"web_search\",    # ì›¹ ê²€ìƒ‰ ê²½ë¡œ\n",
    "        \"vectorstore\": \"retrieve\",     # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ê²½ë¡œ\n",
    "    },\n",
    ")\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„± (ì§ì ‘ ì—°ê²°)\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ â†’ ë¬¸ì„œ í‰ê°€\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# ë¬¸ì„œ í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸°\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",    # ë¬¸ì„œ í‰ê°€ ë…¸ë“œ\n",
    "    decide_to_generate,   # ìƒì„± ì—¬ë¶€ ê²°ì • í•¨ìˆ˜\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # ì§ˆì˜ ì¬ì‘ì„± ê²½ë¡œ\n",
    "        \"generate\": \"generate\",                # ë‹µë³€ ìƒì„± ê²½ë¡œ\n",
    "    },\n",
    ")\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„± â†’ ì¬ê²€ìƒ‰ (ë£¨í”„)\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# ë‹µë³€ ìƒì„± í›„ í’ˆì§ˆ í‰ê°€ ë° ë¶„ê¸°\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",                                    # ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "    grade_generation_v_documents_and_question,    # í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜\n",
    "    {\n",
    "        \"not supported\": \"generate\",        # í™˜ê° ê²€ì¶œ â†’ ì¬ìƒì„±\n",
    "        \"useful\": END,                      # ì„±ê³µ â†’ ì¢…ë£Œ\n",
    "        \"not useful\": \"transform_query\",   # í’ˆì§ˆ ë¶€ì¡± â†’ ì§ˆì˜ ì¬ì‘ì„±\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼ - ì‹¤í–‰ ê°€ëŠ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bce541",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‚¬ìš© (Use Graph)\n",
    "\n",
    "**ì‹¤ì œ í…ŒìŠ¤íŠ¸**: êµ¬í˜„ëœ Adaptive RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ê²€ì¦\n",
    "\n",
    "**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:**\n",
    "1. **ì›¹ ê²€ìƒ‰ ê²½ë¡œ**: ìµœì‹  ìŠ¤í¬ì¸  ì •ë³´ ì§ˆì˜\n",
    "2. **ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ**: AI ì—ì´ì „íŠ¸ ë„ë©”ì¸ ì§€ì‹ ì§ˆì˜\n",
    "\n",
    "**ì„±ëŠ¥ ì§€í‘œ:**\n",
    "- ë¼ìš°íŒ… ì •í™•ë„\n",
    "- ë‹µë³€ í’ˆì§ˆ\n",
    "- ìê¸° ìˆ˜ì • ëŠ¥ë ¥\n",
    "- ì‹¤í–‰ íš¨ìœ¨ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acc541-d726-4b75-84d1-a215845fe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== í…ŒìŠ¤íŠ¸ 1: ì›¹ ê²€ìƒ‰ ê²½ë¡œ ====================\n",
    "# ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸\n",
    "\n",
    "# ì…ë ¥ ì§ˆì˜ - NFL ë“œë˜í”„íŠ¸ëŠ” ì‹œê°„ì— ë¯¼ê°í•œ ìµœì‹  ì •ë³´\n",
    "inputs = {\n",
    "    \"question\": \"What player at the Bears expected to draft first in the 2024 NFL draft?\"\n",
    "}\n",
    "\n",
    "# ì›Œí¬í”Œë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ - ê° ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶œë ¥\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ ì•Œë¦¼\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # ì„ íƒì ìœ¼ë¡œ ì „ì²´ ìƒíƒœ ì¶œë ¥ ê°€ëŠ¥\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# ìµœì¢… ìƒì„± ê²°ê³¼ ì¶œë ¥\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29acc541-d726-4b75-84d1-a215845fe88a-output",
   "metadata": {},
   "source": [
    "---ROUTE QUESTION---\n",
    "---ROUTE QUESTION TO WEB SEARCH---\n",
    "---WEB SEARCH---\n",
    "\"Node 'web_search':\"\n",
    "'\\n---\\n'\n",
    "---GENERATE---\n",
    "---CHECK HALLUCINATIONS---\n",
    "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
    "---GRADE GENERATION vs QUESTION---\n",
    "---DECISION: GENERATION ADDRESSES QUESTION---\n",
    "\"Node 'generate':\"\n",
    "'\\n---\\n'\n",
    "('The Chicago Bears are expected to draft quarterback Caleb Williams first '\n",
    " 'overall in the 2024 NFL Draft. They also have a second first-round pick, '\n",
    " 'where they selected wide receiver Rome Odunze.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== í…ŒìŠ¤íŠ¸ 2: ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ====================\n",
    "# ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•œ ì§ˆë¬¸ìœ¼ë¡œ RAG ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸\n",
    "\n",
    "# ì…ë ¥ ì§ˆì˜ - AI ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ëŠ” ì¸ë±ì‹±ëœ ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œ\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "\n",
    "# ì›Œí¬í”Œë¡œ ì‹¤í–‰ ë° ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # ë…¸ë“œ ì‹¤í–‰ ìƒíƒœ ì¶œë ¥\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # ìƒì„¸ ìƒíƒœ ì •ë³´ëŠ” ì£¼ì„ ì²˜ë¦¬\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# ìµœì¢… ë‹µë³€ ì¶œë ¥\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f-output",
   "metadata": {},
   "source": [
    "---ROUTE QUESTION---\n",
    "---ROUTE QUESTION TO RAG---\n",
    "---RETRIEVE---\n",
    "\"Node 'retrieve':\"\n",
    "'\\n---\\n'\n",
    "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
    "---GRADE: DOCUMENT NOT RELEVANT---\n",
    "---GRADE: DOCUMENT RELEVANT---\n",
    "---GRADE: DOCUMENT NOT RELEVANT---\n",
    "---GRADE: DOCUMENT RELEVANT---\n",
    "---ASSESS GRADED DOCUMENTS---\n",
    "---DECISION: GENERATE---\n",
    "\"Node 'grade_documents':\"\n",
    "'\\n---\\n'\n",
    "---GENERATE---\n",
    "---CHECK HALLUCINATIONS---\n",
    "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
    "---GRADE GENERATION vs QUESTION---\n",
    "---DECISION: GENERATION ADDRESSES QUESTION---\n",
    "\"Node 'generate':\"\n",
    "'\\n---\\n'\n",
    "('The types of agent memory include short-term memory, long-term memory, and '\n",
    " 'sensory memory. Short-term memory is utilized for in-context learning, while '\n",
    " 'long-term memory allows for the retention and recall of information over '\n",
    " 'extended periods. Sensory memory involves learning embedding representations '\n",
    " 'for various raw inputs, such as text and images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ 1 ë¶„ì„: ì›¹ ê²€ìƒ‰ ê²½ë¡œ\n",
    "**ì§ˆë¬¸**: \"What player at the Bears expected to draft first in the 2024 NFL draft?\"\n",
    "\n",
    "**ì‹¤í–‰ ê³¼ì •:**\n",
    "1. âœ… **ë¼ìš°íŒ…**: ìµœì‹  ìŠ¤í¬ì¸  ì •ë³´ â†’ ì›¹ ê²€ìƒ‰ ì˜¬ë°”ë¥¸ ì„ íƒ\n",
    "2. âœ… **ì›¹ ê²€ìƒ‰**: Tavily APIë¡œ ì‹¤ì‹œê°„ ì •ë³´ íšë“\n",
    "3. âœ… **ë‹µë³€ ìƒì„±**: ì •í™•í•œ ì •ë³´ ê¸°ë°˜ ë‹µë³€\n",
    "4. âœ… **í’ˆì§ˆ ê²€ì¦**: í™˜ê° ì—†ìŒ, ì§ˆë¬¸ ì™„ì „ í•´ê²°\n",
    "\n",
    "**ê²°ê³¼**: Caleb Williams 1ìˆœìœ„ ì§€ëª… ì •ë³´ + Rome Odunze ì¶”ê°€ ì •ë³´\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ 2 ë¶„ì„: ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ\n",
    "**ì§ˆë¬¸**: \"What are the types of agent memory?\"\n",
    "\n",
    "**ì‹¤í–‰ ê³¼ì •:**\n",
    "1. âœ… **ë¼ìš°íŒ…**: AI ì—ì´ì „íŠ¸ ì£¼ì œ â†’ ë²¡í„°ìŠ¤í† ì–´ ì˜¬ë°”ë¥¸ ì„ íƒ\n",
    "2. âœ… **ë¬¸ì„œ ê²€ìƒ‰**: 4ê°œ ë¬¸ì„œ ê²€ìƒ‰, 2ê°œ ê´€ë ¨ì„± í†µê³¼\n",
    "3. âœ… **í’ˆì§ˆ í•„í„°ë§**: ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ ìë™ ì œê±°\n",
    "4. âœ… **ë‹µë³€ ìƒì„±**: ë‹¨ê¸°/ì¥ê¸°/ê°ê° ë©”ëª¨ë¦¬ ìƒì„¸ ì„¤ëª…\n",
    "5. âœ… **í’ˆì§ˆ ê²€ì¦**: ë¬¸ì„œ ê¸°ë°˜ ì •í™•í•œ ë‹µë³€ í™•ì¸\n",
    "\n",
    "**ê²°ê³¼**: í¬ê´„ì ì´ê³  ì •í™•í•œ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ìœ í˜• ì„¤ëª…\n",
    "\n",
    "### ğŸš€ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "**ë¼ìš°íŒ… ì •í™•ë„**: 100% (2/2)\n",
    "**í’ˆì§ˆ ê²€ì¦**: ëª¨ë“  ë‹µë³€ì´ í™˜ê° ì—†ì´ ì§ˆë¬¸ í•´ê²°\n",
    "**ìê¸° ìˆ˜ì •**: ë¬¸ì„œ í•„í„°ë§ ì •ìƒ ì‘ë™\n",
    "**íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ì¬ì‹œë„ ì—†ì´ ì§ì ‘ ì„±ê³µ\n",
    "\n",
    "### ğŸ“‹ ë…¼ë¬¸ ëŒ€ë¹„ êµ¬í˜„ íŠ¹ì§•\n",
    "\n",
    "| êµ¬ì„±ìš”ì†Œ | ë…¼ë¬¸ | ë³¸ êµ¬í˜„ |\n",
    "|---------|------|--------|\n",
    "| ë¶„ë¥˜ê¸° | T5-Large (3-class) | GPT-4o-mini (2-class) |\n",
    "| ë¼ìš°íŒ… | A/B/C ë³µì¡ë„ | ì›¹ê²€ìƒ‰/ë²¡í„°ìŠ¤í† ì–´ |\n",
    "| í’ˆì§ˆê²€ì¦ | ê¸°ë³¸ì  | 3ë‹¨ê³„ ê²€ì¦ì‹œìŠ¤í…œ |\n",
    "| ìê¸°ìˆ˜ì • | ì œí•œì  | ë‹¤ì¸µ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ |\n",
    "\n",
    "### ğŸ”„ Adaptive RAG í•µì‹¬ ì‹¤í˜„\n",
    "\n",
    "1. **ì ì‘í˜• ë¼ìš°íŒ…**: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ìµœì  ê²½ë¡œ ì„ íƒ\n",
    "2. **í’ˆì§ˆ ë³´ì¥**: ë‹¤ì¸µ ê²€ì¦ì„ í†µí•œ ì‹ ë¢°ì„± í™•ë³´  \n",
    "3. **ìê¸° ìˆ˜ì •**: ì‹¤íŒ¨ ì‹œ ìë™ ê°œì„  ë° ì¬ì‹œë„\n",
    "4. **íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ì²˜ë¦¬ ì—†ì´ ìµœë‹¨ ê²½ë¡œ ë‹¬ì„±"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
