{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8",
   "metadata": {},
   "source": [
    "# 적응형 RAG (Adaptive RAG)\n",
    "\n",
    "적응형 RAG는 (1) [질의 분석](https://blog.langchain.dev/query-construction/)과 (2) [능동적/자기 수정 RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)를 결합한 RAG 전략입니다.\n",
    "\n",
    "[논문](https://arxiv.org/abs/2403.14403)에서는 다음 3가지 방식 간 라우팅을 위한 질의 분석을 제시합니다:\n",
    "\n",
    "* 검색 없음 (No Retrieval) - 간단한 질문은 검색 없이 직접 답변\n",
    "* 단일 단계 RAG (Single-shot RAG) - 일반적인 RAG 방식으로 한 번 검색 후 답변\n",
    "* 반복적 RAG (Iterative RAG) - 복잡한 질문은 여러 번 검색하여 답변 개선\n",
    "\n",
    "이를 LangGraph를 사용하여 구현해보겠습니다.\n",
    "\n",
    "우리의 구현에서는 다음 두 방식 간 라우팅을 수행합니다:\n",
    "\n",
    "* **웹 검색**: 최신 사건과 관련된 질의용 (실시간 정보 필요)\n",
    "* **자기 수정 RAG**: 우리의 인덱스와 관련된 질의용 (도메인 전문 지식)\n",
    "\n",
    "![Screenshot 2024-03-26 at 1.36.03 PM.png](attachment:36fa621a-9d3d-4860-a17c-5d20e6987481.png)\n",
    "\n",
    "## 🔍 Adaptive RAG 핵심 아이디어\n",
    "\n",
    "**논문에서 제시하는 3-클래스 분류 시스템:**\n",
    "- **클래스 A**: 검색 없이 LLM만으로 답변 가능한 단순 질문\n",
    "- **클래스 B**: 단일 검색으로 답변 가능한 일반적 질문  \n",
    "- **클래스 C**: 다중 검색이 필요한 복잡한 질문\n",
    "\n",
    "**본 구현의 특징:**\n",
    "- T5-Large 분류기 대신 GPT-4o-mini 사용\n",
    "- 품질 검증 시스템 (문서 관련성, 환각 검증, 답변 품질)\n",
    "- 자동 질의 재작성 및 재검색 메커니즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85501ca-eb89-4795-aeab-cdab050ead6b",
   "metadata": {},
   "source": [
    "## 설정 (Setup)\n",
    "\n",
    "먼저 필요한 패키지들을 설치하고 API 키를 설정합니다.\n",
    "\n",
    "**필수 패키지 목록:**\n",
    "- `langchain_community`: 다양한 통합 도구\n",
    "- `tiktoken`: OpenAI 토크나이저\n",
    "- `langchain-openai`: OpenAI 모델 연동\n",
    "- `chromadb`: 벡터 데이터베이스\n",
    "- `langgraph`: 워크플로 그래프 관리\n",
    "- `tavily-python`: 웹 검색 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d1a740-9fea-4a6e-8f95-fb9dbf1c80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# 패키지 설치 (출력 숨김)\n",
    "%%capture --no-stderr\n",
    "%pip install -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub chromadb langchain langgraph  tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f204d-956f-4128-b597-2c698120edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 설정 - 환경변수를 통한 보안적 설정\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    환경변수 설정 함수\n",
    "    \n",
    "    이미 설정된 환경변수가 있으면 건너뛰고,\n",
    "    없으면 사용자에게 입력을 요청하여 설정\n",
    "    \n",
    "    Args:\n",
    "        var: 설정할 환경변수명\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# 필수 API 키 설정\n",
    "_set_env(\"OPENAI_API_KEY\")     # OpenAI GPT 모델 사용을 위한 키\n",
    "# _set_env(\"COHERE_API_KEY\")   # Cohere 임베딩 사용시 필요 (선택사항)\n",
    "_set_env(\"TAVILY_API_KEY\")     # 웹 검색 기능을 위한 Tavily API 키"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e04b18",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">LangGraph 개발을 위한 <a href=\"https://smith.langchain.com\">LangSmith</a> 설정</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        LangSmith에 가입하여 LangGraph 프로젝트의 문제를 신속하게 발견하고 성능을 개선하세요. LangSmith를 사용하면 트레이스 데이터로 LangGraph로 구축한 LLM 앱을 디버그, 테스트, 모니터링할 수 있습니다 — 시작 방법에 대한 자세한 내용은 <a href=\"https://docs.smith.langchain.com\">여기</a>를 참조하세요. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6",
   "metadata": {},
   "source": [
    "## 인덱스 생성 (Create Index)\n",
    "\n",
    "OpenAI Embeddings와 Chroma 벡터 데이터베이스를 사용하여 벡터 인덱스를 구축합니다.\n",
    "\n",
    "**인덱싱 대상 문서:**\n",
    "- AI 에이전트 관련 블로그 포스트\n",
    "- 프롬프트 엔지니어링 기법\n",
    "- LLM 적대적 공격 기법\n",
    "\n",
    "**벡터 인덱스 구축 과정:**\n",
    "1. 웹 문서 로딩\n",
    "2. 토큰 기반 텍스트 분할 (chunk_size=500)\n",
    "3. OpenAI Embeddings로 벡터화\n",
    "4. Chroma 데이터베이스 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 인덱스 구축\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings  # Cohere 임베딩 대안\n",
    "\n",
    "# 임베딩 모델 설정 - OpenAI text-embedding-3-small 사용\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "# 인덱싱할 문서 URL 목록\n",
    "# Lilian Weng의 유명한 AI/ML 연구 블로그 포스트들\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",          # LLM 기반 자율 에이전트\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\", # 프롬프트 엔지니어링 가이드\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",     # LLM 적대적 공격 기법\n",
    "]\n",
    "\n",
    "# 웹 페이지 로딩 - 각 URL에서 문서 내용 추출\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]  # 중첩 리스트 평탄화\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "# tiktoken 기반: OpenAI의 토크나이저 사용으로 정확한 토큰 계산\n",
    "# chunk_size=500: 각 청크의 최대 토큰 수\n",
    "# chunk_overlap=0: 청크 간 겹치는 부분 없음 (메모리 효율적)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Chroma 벡터스토어에 문서 추가\n",
    "# collection_name: 벡터 컬렉션 식별자\n",
    "# embedding: 텍스트를 벡터로 변환하는 모델\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embd,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()  # 검색 인터페이스 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52b427-750c-40f8-8893-e9caab3afd8d",
   "metadata": {},
   "source": [
    "## LLM 모델 설정\n",
    "\n",
    "적응형 RAG 시스템의 핵심 구성요소들을 설정합니다:\n",
    "\n",
    "**주요 LLM 역할:**\n",
    "1. **라우터**: 질의를 웹검색/벡터스토어로 분기\n",
    "2. **평가기**: 문서 관련성, 환각, 답변 품질 검증\n",
    "3. **생성기**: 최종 답변 생성\n",
    "4. **재작성기**: 검색 최적화를 위한 질의 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28baefd-a961-49b0-8394-c5478dadda1c",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">LangChain에서 Pydantic 사용</p>\n",
    "    <p>\n",
    "        이 노트북은 Pydantic v2 <code>BaseModel</code>을 사용하므로 <code>langchain-core >= 0.3</code>이 필요합니다. <code>langchain-core < 0.3</code> 사용 시 Pydantic v1과 v2 <code>BaseModel</code>의 혼재로 인한 오류가 발생합니다.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd5ac0-fa18-4ee9-8051-062a0c56268f",
   "metadata": {},
   "source": [
    "### 질의 분석을 위한 라우터 (Router for Query Analysis)\n",
    "\n",
    "Adaptive RAG의 핵심인 **지능형 라우팅** 시스템을 구현합니다.\n",
    "\n",
    "**라우팅 전략:**\n",
    "- **벡터스토어 라우팅**: 도메인 전문 지식 (AI 에이전트, 프롬프트 엔지니어링, 적대적 공격)\n",
    "- **웹검색 라우팅**: 실시간 정보 필요 (뉴스, 최신 이벤트, 시장 데이터)\n",
    "\n",
    "**논문 vs 구현 차이점:**\n",
    "- 논문: T5-Large 기반 3-클래스 분류기 (A/B/C)\n",
    "- 본 구현: GPT-4o-mini 기반 2-클래스 라우팅 (벡터스토어/웹검색)\n",
    "\n",
    "**Pydantic 구조화된 출력**을 사용하여 일관된 라우팅 결정을 보장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 라우터 구현\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# 라우팅 결정을 위한 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    사용자 질의를 가장 관련성 높은 데이터소스로 라우팅\n",
    "    \n",
    "    Literal 타입으로 가능한 값을 제한하여 \n",
    "    LLM의 출력을 구조화된 형태로 강제\n",
    "    \"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"사용자 질문에 따라 웹 검색 또는 벡터스토어로 라우팅을 선택\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 설정 - 구조화된 출력 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # 일관된 결과를 위해 temperature=0\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 라우팅 결정을 위한 시스템 프롬프트\n",
    "# 명확한 기준을 제시하여 일관된 라우팅 결정 유도\n",
    "system = \"\"\"당신은 사용자 질문을 벡터스토어 또는 웹 검색으로 라우팅하는 전문가입니다.\n",
    "벡터스토어에는 에이전트, 프롬프트 엔지니어링, 그리고 적대적 공격에 관련된 문서들이 포함되어 있습니다.\n",
    "이러한 주제들에 대한 질문은 벡터스토어를 사용하세요. 그렇지 않으면 웹 검색을 사용하세요.\n",
    "\n",
    "### 라우팅 판단 기준:\n",
    "\n",
    "**벡터스토어 사용 (vectorstore):**\n",
    "- AI 에이전트 관련: 메모리, 계획, 도구 사용, 반성, 멀티에이전트 시스템\n",
    "- 프롬프트 엔지니어링: few-shot, chain-of-thought, tree-of-thought, 프롬프트 최적화\n",
    "- LLM 보안: 적대적 프롬프트, jailbreaking, 프롬프트 인젝션, 방어 기법\n",
    "\n",
    "**웹검색 사용 (web_search):**\n",
    "- 실시간/최신 정보: 뉴스, 현재 이벤트, 주식/암호화폐 가격\n",
    "- 시간에 민감한 정보: 날씨, 스포츠 결과, 정치 상황\n",
    "- 위 도메인에 해당하지 않는 일반적인 질문\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 라우팅 체인 구성: 프롬프트 → LLM → 구조화된 출력\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "# 라우팅 테스트 - 다양한 질문 유형에 대한 라우팅 검증\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"Who will the Bears draft first in the NFL draft?\"}  # 최신 스포츠 정보 → 웹검색 예상\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))  # AI 에이전트 → 벡터스토어 예상"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be-output",
   "metadata": {},
   "source": [
    "datasource='web_search'\n",
    "datasource='vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb248c94-0b0c-4d86-8565-32aa8d7424e4",
   "metadata": {},
   "source": [
    "### 검색 평가기 (Retrieval Grader)\n",
    "\n",
    "**품질 보장의 첫 번째 단계**: 검색된 문서의 관련성을 평가합니다.\n",
    "\n",
    "**평가 과정:**\n",
    "1. 벡터스토어에서 문서 검색\n",
    "2. 각 문서와 질문의 관련성 평가\n",
    "3. 관련 없는 문서 필터링\n",
    "4. 관련성 있는 문서만 다음 단계로 전달\n",
    "\n",
    "**평가 기준:**\n",
    "- 키워드 매칭: 질문의 핵심 용어 포함\n",
    "- 의미적 관련성: 질문의 의도와 문서 내용 일치\n",
    "- 엄격하지 않은 평가: 잘못된 검색 결과 제거가 목적\n",
    "\n",
    "이는 Adaptive RAG 논문의 **품질 검증 시스템**을 구현한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856801cb-f42a-44e7-956f-47845e3664ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 검색 평가기\n",
    "\n",
    "\n",
    "# 문서 관련성 평가를 위한 데이터 모델\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"\n",
    "    검색된 문서의 관련성 검사를 위한 이진 평점\n",
    "    \n",
    "    이진 분류로 단순화하여 LLM의 일관된 판단 유도\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"문서가 질문과 관련이 있으면 'yes', 없으면 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 문서 평가용 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 문서 관련성 평가를 위한 시스템 프롬프트\n",
    "# 관대한 평가 기준으로 설정 - 완전히 관련 없는 문서만 필터링\n",
    "system = \"\"\"당신은 검색된 문서와 사용자 질문의 관련성을 평가하는 평가자입니다. \\n \n",
    "    문서가 사용자 질문과 관련된 키워드나 의미적 내용을 포함하고 있다면 관련이 있다고 평가하세요. \\n\n",
    "    엄격한 테스트일 필요는 없습니다. 목표는 잘못된 검색 결과를 걸러내는 것입니다. \\n\n",
    "    문서가 질문과 관련이 있는지를 나타내는 이진 점수 'yes' 또는 'no'를 제공하세요.\n",
    "    \n",
    "    ### 평가 가이드라인:\n",
    "    \n",
    "    **'yes' 조건 (관련 있음):**\n",
    "    - 질문의 핵심 키워드나 개념이 문서에 명시적으로 언급됨\n",
    "    - 질문과 의미적으로 관련된 내용이나 맥락 포함\n",
    "    - 질문에 답변하는데 도움이 될 수 있는 정보 존재\n",
    "    - 동의어나 관련 용어를 통한 간접적 연관성\n",
    "    \n",
    "    **'no' 조건 (관련 없음):**\n",
    "    - 질문과 완전히 다른 주제나 도메인\n",
    "    - 키워드는 있지만 완전히 다른 맥락에서 사용됨\n",
    "    - 질문에 답변하는데 전혀 도움이 되지 않는 내용\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"검색된 문서: \\n\\n {document} \\n\\n 사용자 질문: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 검색 평가 체인 구성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# 평가 테스트 수행\n",
    "question = \"agent memory\"  # AI 에이전트 메모리에 관한 질문\n",
    "docs = retriever.invoke(question)  # 벡터스토어에서 관련 문서 검색\n",
    "doc_txt = docs[1].page_content  # 두 번째 검색 결과 사용\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "856801cb-f42a-44e7-956f-47845e3664ca-output",
   "metadata": {},
   "source": [
    "binary_score='yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "source": [
    "### 생성 (Generate)\n",
    "\n",
    "**RAG의 핵심**: 검색된 문서를 바탕으로 질문에 대한 답변을 생성합니다.\n",
    "\n",
    "**생성 과정:**\n",
    "1. 관련성이 검증된 문서들을 컨텍스트로 결합\n",
    "2. LangChain Hub의 검증된 RAG 프롬프트 사용\n",
    "3. GPT-4o-mini로 답변 생성\n",
    "4. 문자열 파서로 최종 텍스트 출력\n",
    "\n",
    "**프롬프트 최적화:**\n",
    "- `rlm/rag-prompt`: 커뮤니티 검증된 RAG 프롬프트 템플릿\n",
    "- 컨텍스트와 질문을 효과적으로 구조화\n",
    "- 환각 최소화를 위한 지시사항 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 생성\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain Hub에서 검증된 RAG 프롬프트 가져오기\n",
    "# 이 프롬프트는 컨텍스트와 질문을 받아 정확한 답변을 생성하도록 최적화됨\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 답변 생성용 LLM 설정\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    검색된 문서들을 하나의 컨텍스트 문자열로 결합\n",
    "    \n",
    "    각 문서를 두 줄 간격(\\n\\n)으로 구분하여\n",
    "    LLM이 서로 다른 문서임을 인식하도록 함\n",
    "    \n",
    "    Args:\n",
    "        docs: Document 객체들의 리스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 결합된 컨텍스트 문자열\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 구성: 프롬프트 → LLM → 문자열 파서\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 답변 생성 실행\n",
    "docs_txt = format_docs(docs)  # 검색된 문서들을 컨텍스트로 변환\n",
    "generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8-output",
   "metadata": {},
   "source": [
    "Agent memory in LLM-powered autonomous systems consists of short-term and long-term memory. Short-term memory utilizes in-context learning for immediate tasks, while long-term memory allows agents to retain and recall information over extended periods, often using external storage for efficient retrieval. This memory structure supports the agent's ability to reflect on past actions and improve future performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ab54a-4a4f-45fa-b1c5-cea1bf4c59d5",
   "metadata": {},
   "source": [
    "### 환각 평가기 (Hallucination Grader)\n",
    "\n",
    "**품질 보장의 두 번째 단계**: 생성된 답변이 검색된 사실에 근거하는지 검증합니다.\n",
    "\n",
    "**환각 검증 과정:**\n",
    "1. 생성된 답변의 모든 주장 분석\n",
    "2. 각 주장이 제공된 문서에서 뒷받침되는지 확인\n",
    "3. 문서에 없는 정보 추가 여부 검사\n",
    "4. 사실 왜곡이나 잘못된 해석 검출\n",
    "\n",
    "**환각의 유형:**\n",
    "- **정보 부족 환각**: 문서에 없는 내용 생성\n",
    "- **해석 오류**: 문서 내용의 잘못된 해석\n",
    "- **과도한 일반화**: 제한적 정보의 확대 해석\n",
    "\n",
    "이는 **Self-Corrective RAG**의 핵심 구성요소입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 환각 평가기\n",
    "\n",
    "\n",
    "# 환각 검출을 위한 데이터 모델\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"\n",
    "    생성된 답변의 환각 여부 검사\n",
    "    \n",
    "    환각: 제공된 문서에 근거하지 않은 정보를 생성하는 현상\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"답변이 사실에 근거하고 있으면 'yes', 환각이 있으면 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 환각 평가용 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# 환각 검증을 위한 시스템 프롬프트\n",
    "# 엄격한 기준으로 환각 검출 - 문서에 명시된 내용만 허용\n",
    "system = \"\"\"당신은 LLM의 생성 결과가 검색된 사실들에 근거하는지/지원되는지 평가하는 평가자입니다. \\n \n",
    "     이진 점수 'yes' 또는 'no'를 제공하세요. 'Yes'는 답변이 사실들에 근거하고 있음/지원되고 있음을 의미합니다.\n",
    "     \n",
    "     ### 환각 검출 기준:\n",
    "     \n",
    "     **'yes' 조건 (사실 근거):**\n",
    "     - 생성된 답변의 모든 주장이 제공된 문서에서 직접 확인 가능\n",
    "     - 문서의 내용을 정확하게 요약하고 해석\n",
    "     - 추론이 있더라도 문서 내용에 논리적으로 기반\n",
    "     - 불확실한 경우 적절히 한정적 표현 사용\n",
    "     \n",
    "     **'no' 조건 (환각 존재):**\n",
    "     - 문서에 전혀 언급되지 않은 구체적 사실이나 수치 포함\n",
    "     - 문서의 내용을 명백히 잘못 해석하거나 왜곡\n",
    "     - 문서의 범위를 벗어난 확정적 주장\n",
    "     - 상식적 지식이라도 문서와 모순되는 내용\"\"\"\n",
    "     \n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"사실 집합: \\n\\n {documents} \\n\\n LLM 생성 결과: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 환각 평가 체인 구성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "# 환각 검증 테스트\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3-output",
   "metadata": {},
   "source": [
    "GradeHallucinations(binary_score='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58502a-c25f-4d80-a402-5583b0cd3e41",
   "metadata": {},
   "source": [
    "### 답변 평가기 (Answer Grader)\n",
    "\n",
    "**품질 보장의 마지막 단계**: 생성된 답변이 원래 질문을 적절히 해결하는지 평가합니다.\n",
    "\n",
    "**답변 품질 평가 기준:**\n",
    "1. **완전성**: 질문의 모든 측면을 다룸\n",
    "2. **정확성**: 질문의 의도를 올바르게 이해\n",
    "3. **관련성**: 질문과 직접적으로 관련된 답변\n",
    "4. **명확성**: 이해하기 쉽고 구체적인 답변\n",
    "\n",
    "**평가 과정:**\n",
    "- 질문의 핵심 의도 파악\n",
    "- 답변의 충실도 검사\n",
    "- 추가 정보 필요성 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded99680-437a-4c9d-b860-619c88949d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 답변 평가기\n",
    "\n",
    "\n",
    "# 답변 품질 평가를 위한 데이터 모델\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    답변이 질문을 해결하는지 평가\n",
    "    \n",
    "    환각 검증과는 별개로, 답변의 실제 유용성을 평가\n",
    "    \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"답변이 질문을 해결하면 'yes', 해결하지 못하면 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 답변 평가용 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# 답변 품질 평가를 위한 시스템 프롬프트\n",
    "# 사용자 관점에서의 답변 유용성 평가\n",
    "system = \"\"\"당신은 답변이 질문을 해결하는지/해결하는지 평가하는 평가자입니다 \\n \n",
    "     이진 점수 'yes' 또는 'no'를 제공하세요. 'Yes'는 답변이 질문을 해결함을 의미합니다.\n",
    "     \n",
    "     ### 답변 품질 평가 기준:\n",
    "     \n",
    "     **'yes' 조건 (만족스러운 답변):**\n",
    "     - 질문의 핵심 내용과 의도를 정확히 다룸\n",
    "     - 질문에서 요구하는 구체적 정보나 설명 제공\n",
    "     - 질문의 맥락과 수준에 적합한 답변\n",
    "     - 완전하고 이해하기 쉬운 답변\n",
    "     - 질문자가 원하는 바를 충족\n",
    "     \n",
    "     **'no' 조건 (불만족스러운 답변):**\n",
    "     - 질문과 관련 없는 내용으로만 구성\n",
    "     - 질문의 핵심을 놓치거나 피해간 답변\n",
    "     - 너무 일반적이거나 모호한 답변\n",
    "     - 불완전하여 추가 질문이 필요한 답변\n",
    "     - 질문의 의도를 완전히 오해한 답변\"\"\"\n",
    "     \n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"사용자 질문: \\n\\n {question} \\n\\n LLM 생성 결과: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 답변 평가 체인 구성\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "\n",
    "# 답변 품질 평가 테스트\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ded99680-437a-4c9d-b860-619c88949d84-output",
   "metadata": {},
   "source": [
    "GradeAnswer(binary_score='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77946c-2646-4039-86b0-e2fde1ab7459",
   "metadata": {},
   "source": [
    "### 질의 재작성 (Question Rewriting)\n",
    "\n",
    "**자기 수정 메커니즘**: 검색 실패 시 질문을 재작성하여 더 나은 검색 결과를 얻습니다.\n",
    "\n",
    "**재작성이 필요한 경우:**\n",
    "1. 관련 문서를 찾지 못한 경우\n",
    "2. 답변 품질이 만족스럽지 않은 경우\n",
    "3. 환각이 검출된 경우\n",
    "\n",
    "**재작성 전략:**\n",
    "- **키워드 최적화**: 검색에 효과적인 핵심 용어 추가\n",
    "- **의미 명확화**: 모호한 표현을 구체적으로 변환\n",
    "- **검색 친화적 형태**: 벡터 유사성 검색에 적합한 구조\n",
    "- **도메인 용어**: 전문 분야 용어로 정확성 향상\n",
    "\n",
    "**예시 변환:**\n",
    "- \"메모리가 뭐야?\" → \"AI 에이전트의 메모리 시스템과 종류는 무엇인가?\"\n",
    "- \"어떻게 해?\" → \"프롬프트 엔지니어링에서 few-shot learning을 어떻게 구현하는가?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 질의 재작성기\n",
    "\n",
    "# 질의 재작성용 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 질의 재작성을 위한 시스템 프롬프트\n",
    "# 벡터 검색 최적화에 특화된 재작성 지침\n",
    "system = \"\"\"당신은 입력 질문을 벡터스토어 검색에 최적화된 더 나은 버전으로 변환하는 질문 재작성기입니다. \\n \n",
    "     입력을 보고 그 근본적인 의미적 의도/의미에 대해 추론해보세요.\n",
    "     \n",
    "     ### 재작성 최적화 원칙:\n",
    "     \n",
    "     **1. 키워드 강화:**\n",
    "     - 검색에 중요한 도메인 특화 용어 포함\n",
    "     - 동의어와 관련 용어 활용\n",
    "     - 구체적이고 기술적인 용어 선호\n",
    "     \n",
    "     **2. 구조적 명확화:**\n",
    "     - 모호한 대명사나 지시어 제거\n",
    "     - 완전한 문장 구조 사용\n",
    "     - 검색 의도를 명시적으로 표현\n",
    "     \n",
    "     **3. 맥락 보강:**\n",
    "     - 필요시 도메인 컨텍스트 추가\n",
    "     - 질문의 범위와 깊이 명확화\n",
    "     - 기술적 수준 명시\n",
    "     \n",
    "     **4. 검색 친화성:**\n",
    "     - 벡터 임베딩에 유리한 표현 사용\n",
    "     - 의미적 밀도 높은 구문 구성\n",
    "     - 검색 가능한 개념들로 분해\n",
    "     \n",
    "     ### 도메인별 재작성 예시:\n",
    "     \n",
    "     **AI 에이전트:**\n",
    "     - \"메모리\" → \"AI 에이전트의 메모리 시스템 아키텍처와 장단기 메모리 메커니즘\"\n",
    "     - \"계획\" → \"AI 에이전트의 계획 수립 알고리즘과 목표 분해 전략\"\n",
    "     \n",
    "     **프롬프트 엔지니어링:**\n",
    "     - \"좋은 프롬프트\" → \"효과적인 프롬프트 설계 원칙과 few-shot learning 기법\"\n",
    "     - \"개선 방법\" → \"프롬프트 최적화 기법과 성능 향상 전략\"\n",
    "     \n",
    "     **보안:**\n",
    "     - \"공격\" → \"LLM 적대적 프롬프트 공격 기법과 방어 메커니즘\"\n",
    "     - \"안전성\" → \"프롬프트 인젝션 방지 및 보안 강화 방안\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"다음은 초기 질문입니다: \\n\\n {question} \\n 벡터 검색에 최적화된 개선된 질문을 작성하세요.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 질의 재작성 체인 구성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 질의 재작성 테스트\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e-output",
   "metadata": {},
   "source": [
    "'What are the key concepts and techniques related to agent memory in artificial intelligence?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c0b31-b919-4498-869f-9673125c2473",
   "metadata": {},
   "source": [
    "## 웹 검색 도구 (Web Search Tool)\n",
    "\n",
    "**실시간 정보 획득**: Tavily Search API를 통한 최신 정보 검색\n",
    "\n",
    "**Tavily 선택 이유:**\n",
    "- LLM 친화적 검색 결과 제공\n",
    "- 구조화된 데이터 반환\n",
    "- 높은 품질의 콘텐츠 필터링\n",
    "- API 기반 안정적 서비스\n",
    "\n",
    "**검색 설정:**\n",
    "- `k=3`: 상위 3개 결과만 반환 (관련성과 효율성 균형)\n",
    "- 자동 콘텐츠 정제 및 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d829bb-1074-4976-b650-ead41dcb9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 검색\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily 웹 검색 도구 설정\n",
    "# k=3: 최상위 3개 검색 결과만 반환\n",
    "# 토큰 사용량과 정보 품질의 최적 균형점\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4",
   "metadata": {},
   "source": [
    "## 그래프 구성 (Construct the Graph)\n",
    "\n",
    "**LangGraph를 사용한 워크플로 설계**: 복잡한 RAG 시스템을 상태 기반 그래프로 구현\n",
    "\n",
    "**그래프 설계 철학:**\n",
    "- **상태 중심**: 모든 정보를 그래프 상태로 관리\n",
    "- **조건부 분기**: 동적 워크플로 경로 결정\n",
    "- **자기 수정**: 품질 검증 실패 시 자동 재시도\n",
    "- **모듈화**: 각 단계를 독립적인 노드로 분리\n",
    "\n",
    "### 그래프 상태 정의 (Define Graph State)\n",
    "\n",
    "**StateGraph의 핵심**: 모든 노드가 공유하는 데이터 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723fcdb-06e6-402d-912e-899795b78408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Adaptive RAG 그래프의 전역 상태 정의\n",
    "    \n",
    "    TypedDict를 사용하여 타입 안전성 보장\n",
    "    모든 노드가 이 상태를 공유하고 수정 가능\n",
    "\n",
    "    Attributes:\n",
    "        question: 현재 처리 중인 사용자 질문 (원본 또는 재작성됨)\n",
    "        generation: LLM이 생성한 최종 답변\n",
    "        documents: 검색된 관련 문서들의 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    question: str          # 사용자 질문 - 재작성될 수 있음\n",
    "    generation: str        # 생성된 답변 - 재생성될 수 있음\n",
    "    documents: List[str]   # 검색 문서 - 필터링될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d6c0d-42e8-4399-9751-e315be16607a",
   "metadata": {},
   "source": [
    "### 그래프 플로우 정의 (Define Graph Flow)\n",
    "\n",
    "**노드 함수 설계**: 각 처리 단계를 독립적인 함수로 구현\n",
    "\n",
    "**설계 원칙:**\n",
    "- **순수 함수**: 부작용 없는 상태 변환\n",
    "- **명확한 입출력**: 상태 딕셔너리 입력/출력\n",
    "- **로깅**: 각 단계의 실행 상태 출력\n",
    "- **오류 처리**: 예외 상황 대응\n",
    "\n",
    "**노드 유형:**\n",
    "1. **처리 노드**: 실제 작업 수행 (retrieve, generate, etc.)\n",
    "2. **평가 노드**: 품질 검증 (grade_documents)\n",
    "3. **변환 노드**: 데이터 변환 (transform_query)\n",
    "4. **분기 함수**: 조건부 라우팅 (route_question, decide_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ==================== 핵심 처리 노드들 ====================\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    벡터스토어에서 관련 문서 검색\n",
    "    \n",
    "    검색 과정:\n",
    "    1. 현재 질문을 임베딩으로 변환\n",
    "    2. 벡터 유사성 기반 문서 검색\n",
    "    3. 상위 k개 문서 반환 (기본값 사용)\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): documents 키에 검색된 문서들 추가\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 벡터스토어 검색 실행\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    검색된 문서를 바탕으로 답변 생성\n",
    "    \n",
    "    생성 과정:\n",
    "    1. 문서들을 단일 컨텍스트로 결합\n",
    "    2. RAG 프롬프트에 컨텍스트와 질문 입력\n",
    "    3. LLM으로 답변 생성\n",
    "    4. 후처리 및 정제\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): generation 키에 생성된 답변 추가\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 방식 답변 생성\n",
    "    docs_txt = format_docs(documents)\n",
    "    generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    검색된 문서들의 질문 관련성 평가 및 필터링\n",
    "    \n",
    "    품질 보장 과정:\n",
    "    1. 각 문서별로 관련성 점수 계산\n",
    "    2. 임계값 기준 관련 문서만 선별\n",
    "    3. 필터링된 문서 리스트 반환\n",
    "    4. 통계 정보 로깅\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): 필터링된 문서로 documents 키 업데이트\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서별 관련성 평가\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    검색 성능 향상을 위한 질의 재작성\n",
    "    \n",
    "    재작성 전략:\n",
    "    1. 원본 질문의 의도 분석\n",
    "    2. 검색 친화적 키워드 추가\n",
    "    3. 모호한 표현 명확화\n",
    "    4. 도메인 특화 용어 적용\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): 재작성된 질문으로 question 키 업데이트\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 질의 재작성 실행\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Tavily API를 통한 웹 검색 수행\n",
    "    \n",
    "    웹 검색 과정:\n",
    "    1. 질문을 검색 쿼리로 변환\n",
    "    2. Tavily API 호출\n",
    "    3. 검색 결과 정제 및 구조화\n",
    "    4. Document 객체로 변환\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): 웹 검색 결과로 documents 키 업데이트\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Tavily 웹 검색 실행\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    # 검색 결과를 단일 문서로 결합\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "    return {\"documents\": web_results, \"question\": question}\n",
    "\n",
    "\n",
    "# ==================== 조건부 분기 함수들 ====================\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    질문을 웹 검색 또는 RAG로 라우팅\n",
    "    \n",
    "    라우팅 로직:\n",
    "    1. 질문을 라우터 LLM에 입력\n",
    "    2. 구조화된 출력으로 라우팅 결정 받음\n",
    "    3. 결정에 따라 다음 노드 지정\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 다음 노드 이름 (\"web_search\" 또는 \"vectorstore\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    문서 평가 결과에 따른 다음 단계 결정\n",
    "    \n",
    "    결정 로직:\n",
    "    - 관련 문서 존재: 답변 생성 단계로 진행\n",
    "    - 관련 문서 없음: 질의 재작성 후 재검색\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 다음 노드 이름 (\"generate\" 또는 \"transform_query\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성 검사에서 필터링됨\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련 문서 존재, 답변 생성 진행\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    생성된 답변의 품질 종합 평가\n",
    "    \n",
    "    2단계 품질 검증:\n",
    "    1. 환각 검증: 답변이 문서에 근거하는가?\n",
    "    2. 답변 품질: 질문을 적절히 해결하는가?\n",
    "    \n",
    "    종합 판정:\n",
    "    - 두 검증 모두 통과: 성공적 완료\n",
    "    - 환각 검출: 재생성 필요\n",
    "    - 답변 부족: 질의 재작성 후 재시도\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 다음 행동 (\"useful\", \"not supported\", \"not useful\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 1단계: 환각 검증\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        # 2단계: 답변 품질 검증\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f",
   "metadata": {},
   "source": [
    "### 그래프 컴파일 (Compile Graph)\n",
    "\n",
    "**워크플로 구성**: 노드와 엣지를 연결하여 실행 가능한 그래프 생성\n",
    "\n",
    "**그래프 구조:**\n",
    "```\n",
    "START → route_question\n",
    "├── web_search → generate → quality_check → END\n",
    "└── vectorstore → retrieve → grade_docs → decide\n",
    "    ├── transform_query → retrieve (재시도)\n",
    "    └── generate → quality_check\n",
    "        ├── useful → END\n",
    "        ├── not_useful → transform_query\n",
    "        └── not_supported → generate\n",
    "```\n",
    "\n",
    "**엣지 유형:**\n",
    "1. **고정 엣지**: 항상 같은 노드로 이동\n",
    "2. **조건부 엣지**: 조건에 따라 다른 노드로 분기\n",
    "3. **루프 엣지**: 품질 향상을 위한 재시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# StateGraph 인스턴스 생성 - GraphState 타입 사용\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ==================== 노드 등록 ====================\n",
    "# 각 노드는 특정 기능을 담당하는 함수와 매핑\n",
    "\n",
    "workflow.add_node(\"web_search\", web_search)           # 웹 검색 노드\n",
    "workflow.add_node(\"retrieve\", retrieve)               # 벡터스토어 검색 노드\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # 문서 관련성 평가 노드\n",
    "workflow.add_node(\"generate\", generate)               # 답변 생성 노드\n",
    "workflow.add_node(\"transform_query\", transform_query) # 질의 재작성 노드\n",
    "\n",
    "# ==================== 엣지 구성 ====================\n",
    "\n",
    "# 시작점에서 라우팅 결정\n",
    "workflow.add_conditional_edges(\n",
    "    START,           # 시작 노드\n",
    "    route_question,  # 라우팅 함수\n",
    "    {\n",
    "        \"web_search\": \"web_search\",    # 웹 검색 경로\n",
    "        \"vectorstore\": \"retrieve\",     # 벡터스토어 검색 경로\n",
    "    },\n",
    ")\n",
    "\n",
    "# 웹 검색 → 답변 생성 (직접 연결)\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "\n",
    "# 벡터스토어 검색 → 문서 평가\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 문서 평가 결과에 따른 분기\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",    # 문서 평가 노드\n",
    "    decide_to_generate,   # 생성 여부 결정 함수\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # 질의 재작성 경로\n",
    "        \"generate\": \"generate\",                # 답변 생성 경로\n",
    "    },\n",
    ")\n",
    "\n",
    "# 질의 재작성 → 재검색 (루프)\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# 답변 생성 후 품질 평가 및 분기\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",                                    # 답변 생성 노드\n",
    "    grade_generation_v_documents_and_question,    # 품질 평가 함수\n",
    "    {\n",
    "        \"not supported\": \"generate\",        # 환각 검출 → 재생성\n",
    "        \"useful\": END,                      # 성공 → 종료\n",
    "        \"not useful\": \"transform_query\",   # 품질 부족 → 질의 재작성\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일 - 실행 가능한 애플리케이션 생성\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bce541",
   "metadata": {},
   "source": [
    "## 그래프 사용 (Use Graph)\n",
    "\n",
    "**실제 테스트**: 구현된 Adaptive RAG 시스템의 성능 검증\n",
    "\n",
    "**테스트 시나리오:**\n",
    "1. **웹 검색 경로**: 최신 스포츠 정보 질의\n",
    "2. **벡터스토어 경로**: AI 에이전트 도메인 지식 질의\n",
    "\n",
    "**성능 지표:**\n",
    "- 라우팅 정확도\n",
    "- 답변 품질\n",
    "- 자기 수정 능력\n",
    "- 실행 효율성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acc541-d726-4b75-84d1-a215845fe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 테스트 1: 웹 검색 경로 ====================\n",
    "# 최신 정보가 필요한 질문으로 웹 검색 라우팅 테스트\n",
    "\n",
    "# 입력 질의 - NFL 드래프트는 시간에 민감한 최신 정보\n",
    "inputs = {\n",
    "    \"question\": \"What player at the Bears expected to draft first in the 2024 NFL draft?\"\n",
    "}\n",
    "\n",
    "# 워크플로 스트리밍 실행 - 각 단계별 진행 상황 실시간 출력\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 노드 실행 완료 알림\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # 선택적으로 전체 상태 출력 가능\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# 최종 생성 결과 출력\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29acc541-d726-4b75-84d1-a215845fe88a-output",
   "metadata": {},
   "source": [
    "---ROUTE QUESTION---\n",
    "---ROUTE QUESTION TO WEB SEARCH---\n",
    "---WEB SEARCH---\n",
    "\"Node 'web_search':\"\n",
    "'\\n---\\n'\n",
    "---GENERATE---\n",
    "---CHECK HALLUCINATIONS---\n",
    "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
    "---GRADE GENERATION vs QUESTION---\n",
    "---DECISION: GENERATION ADDRESSES QUESTION---\n",
    "\"Node 'generate':\"\n",
    "'\\n---\\n'\n",
    "('The Chicago Bears are expected to draft quarterback Caleb Williams first '\n",
    " 'overall in the 2024 NFL Draft. They also have a second first-round pick, '\n",
    " 'where they selected wide receiver Rome Odunze.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 테스트 2: 벡터스토어 경로 ====================\n",
    "# 도메인 전문 지식이 필요한 질문으로 RAG 라우팅 테스트\n",
    "\n",
    "# 입력 질의 - AI 에이전트 메모리는 인덱싱된 문서의 핵심 주제\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "\n",
    "# 워크플로 실행 및 진행 상황 출력\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 노드 실행 상태 출력\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # 상세 상태 정보는 주석 처리\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# 최종 답변 출력\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f-output",
   "metadata": {},
   "source": [
    "---ROUTE QUESTION---\n",
    "---ROUTE QUESTION TO RAG---\n",
    "---RETRIEVE---\n",
    "\"Node 'retrieve':\"\n",
    "'\\n---\\n'\n",
    "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
    "---GRADE: DOCUMENT NOT RELEVANT---\n",
    "---GRADE: DOCUMENT RELEVANT---\n",
    "---GRADE: DOCUMENT NOT RELEVANT---\n",
    "---GRADE: DOCUMENT RELEVANT---\n",
    "---ASSESS GRADED DOCUMENTS---\n",
    "---DECISION: GENERATE---\n",
    "\"Node 'grade_documents':\"\n",
    "'\\n---\\n'\n",
    "---GENERATE---\n",
    "---CHECK HALLUCINATIONS---\n",
    "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
    "---GRADE GENERATION vs QUESTION---\n",
    "---DECISION: GENERATION ADDRESSES QUESTION---\n",
    "\"Node 'generate':\"\n",
    "'\\n---\\n'\n",
    "('The types of agent memory include short-term memory, long-term memory, and '\n",
    " 'sensory memory. Short-term memory is utilized for in-context learning, while '\n",
    " 'long-term memory allows for the retention and recall of information over '\n",
    " 'extended periods. Sensory memory involves learning embedding representations '\n",
    " 'for various raw inputs, such as text and images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 🎯 테스트 결과 분석\n",
    "\n",
    "### 테스트 1 분석: 웹 검색 경로\n",
    "**질문**: \"What player at the Bears expected to draft first in the 2024 NFL draft?\"\n",
    "\n",
    "**실행 과정:**\n",
    "1. ✅ **라우팅**: 최신 스포츠 정보 → 웹 검색 올바른 선택\n",
    "2. ✅ **웹 검색**: Tavily API로 실시간 정보 획득\n",
    "3. ✅ **답변 생성**: 정확한 정보 기반 답변\n",
    "4. ✅ **품질 검증**: 환각 없음, 질문 완전 해결\n",
    "\n",
    "**결과**: Caleb Williams 1순위 지명 정보 + Rome Odunze 추가 정보\n",
    "\n",
    "### 테스트 2 분석: 벡터스토어 경로\n",
    "**질문**: \"What are the types of agent memory?\"\n",
    "\n",
    "**실행 과정:**\n",
    "1. ✅ **라우팅**: AI 에이전트 주제 → 벡터스토어 올바른 선택\n",
    "2. ✅ **문서 검색**: 4개 문서 검색, 2개 관련성 통과\n",
    "3. ✅ **품질 필터링**: 관련 없는 문서 자동 제거\n",
    "4. ✅ **답변 생성**: 단기/장기/감각 메모리 상세 설명\n",
    "5. ✅ **품질 검증**: 문서 기반 정확한 답변 확인\n",
    "\n",
    "**결과**: 포괄적이고 정확한 에이전트 메모리 유형 설명\n",
    "\n",
    "### 🚀 시스템 성능 평가\n",
    "\n",
    "**라우팅 정확도**: 100% (2/2)\n",
    "**품질 검증**: 모든 답변이 환각 없이 질문 해결\n",
    "**자기 수정**: 문서 필터링 정상 작동\n",
    "**효율성**: 불필요한 재시도 없이 직접 성공\n",
    "\n",
    "### 📋 논문 대비 구현 특징\n",
    "\n",
    "| 구성요소 | 논문 | 본 구현 |\n",
    "|---------|------|--------|\n",
    "| 분류기 | T5-Large (3-class) | GPT-4o-mini (2-class) |\n",
    "| 라우팅 | A/B/C 복잡도 | 웹검색/벡터스토어 |\n",
    "| 품질검증 | 기본적 | 3단계 검증시스템 |\n",
    "| 자기수정 | 제한적 | 다층 재시도 메커니즘 |\n",
    "\n",
    "### 🔄 Adaptive RAG 핵심 실현\n",
    "\n",
    "1. **적응형 라우팅**: 질문 유형에 따른 최적 경로 선택\n",
    "2. **품질 보장**: 다층 검증을 통한 신뢰성 확보  \n",
    "3. **자기 수정**: 실패 시 자동 개선 및 재시도\n",
    "4. **효율성**: 불필요한 처리 없이 최단 경로 달성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
