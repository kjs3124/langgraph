{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8",
   "metadata": {},
   "source": "# ì ì‘í˜• RAG (Adaptive RAG)\n\nì ì‘í˜• RAGëŠ” (1) [ì§ˆì˜ ë¶„ì„](https://blog.langchain.dev/query-construction/)ê³¼ (2) [ëŠ¥ë™ì /ìê¸° ìˆ˜ì • RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)ë¥¼ ê²°í•©í•œ RAG ì „ëµì…ë‹ˆë‹¤.\n\n[ë…¼ë¬¸](https://arxiv.org/abs/2403.14403)ì—ì„œëŠ” ë‹¤ìŒ 3ê°€ì§€ ë°©ì‹ ê°„ ë¼ìš°íŒ…ì„ ìœ„í•œ ì§ˆì˜ ë¶„ì„ì„ ì œì‹œí•©ë‹ˆë‹¤:\n\n* ê²€ìƒ‰ ì—†ìŒ (No Retrieval)\n* ë‹¨ì¼ ë‹¨ê³„ RAG (Single-shot RAG)  \n* ë°˜ë³µì  RAG (Iterative RAG)\n\nì´ë¥¼ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n\nìš°ë¦¬ì˜ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìŒ ë‘ ë°©ì‹ ê°„ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n\n* ì›¹ ê²€ìƒ‰: ìµœì‹  ì‚¬ê±´ê³¼ ê´€ë ¨ëœ ì§ˆì˜ìš©\n* ìê¸° ìˆ˜ì • RAG: ìš°ë¦¬ì˜ ì¸ë±ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆì˜ìš©\n\n![Screenshot 2024-03-26 at 1.36.03 PM.png](attachment:36fa621a-9d3d-4860-a17c-5d20e6987481.png)\n\n## ğŸ“– êµ¬í˜„ ê°œìš”\n\në³¸ ë…¸íŠ¸ë¶ì€ Adaptive-RAG ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ LangGraphë¡œ êµ¬í˜„í•˜ì—¬ ë‹¤ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤:\n- ì§ˆì˜ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘í˜• ì²˜ë¦¬\n- í’ˆì§ˆ ë³´ì¥ì„ ìœ„í•œ ë‹¤ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ\n- ìë™ ì§ˆì˜ ê°œì„  ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜"
  },
  {
   "cell_type": "markdown",
   "id": "a85501ca-eb89-4795-aeab-cdab050ead6b",
   "metadata": {},
   "source": [
    "## ì„¤ì • (Setup)\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1a740-9fea-4a6e-8f95-fb9dbf1c80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì¶œë ¥ ìˆ¨ê¹€)\n",
    "%%capture --no-stderr\n",
    "%pip install -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub chromadb langchain langgraph  tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f204d-956f-4128-b597-2c698120edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•¨ìˆ˜ - ì´ë¯¸ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì…ë ¥ ìš”ì²­\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# í•„ìˆ˜ API í‚¤ë“¤ ì„¤ì •\n",
    "_set_env(\"OPENAI_API_KEY\")     # OpenAI GPT ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ í‚¤\n",
    "# _set_env(\"COHERE_API_KEY\")   # Cohere ì„ë² ë”© ì‚¬ìš©ì‹œ í•„ìš” (ì„ íƒì‚¬í•­)\n",
    "_set_env(\"TAVILY_API_KEY\")     # ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•œ Tavily API í‚¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e04b18",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">LangGraph ê°œë°œì„ ìœ„í•œ <a href=\"https://smith.langchain.com\">LangSmith</a> ì„¤ì •</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        LangSmithì— ê°€ì…í•˜ì—¬ LangGraph í”„ë¡œì íŠ¸ì˜ ë¬¸ì œë¥¼ ì‹ ì†í•˜ê²Œ ë°œê²¬í•˜ê³  ì„±ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°ë¡œ LangGraphë¡œ êµ¬ì¶•í•œ LLM ì•±ì„ ë””ë²„ê·¸, í…ŒìŠ¤íŠ¸, ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€” ì‹œì‘ ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ <a href=\"https://docs.smith.langchain.com\">ì—¬ê¸°</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6",
   "metadata": {},
   "source": [
    "## ì¸ë±ìŠ¤ ìƒì„± (Create Index)\n",
    "\n",
    "OpenAI Embeddingsì™€ Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  \n",
    "ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ê´€ë ¨ëœ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì˜ URLì„ ì…ë ¥í•©ë‹ˆë‹¤.  \n",
    "ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì— ì‚¬ìš©í•  ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings  # Cohere ì„ë² ë”© ì‚¬ìš©ì‹œ\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (OpenAI ì„ë² ë”© ì‚¬ìš©)\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "# ì¸ë±ì‹±í•  ë¬¸ì„œë“¤ì˜ URL ëª©ë¡\n",
    "# Lilian Wengì˜ ìœ ëª…í•œ AI/ML ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë“¤\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",          # AI ì—ì´ì „íŠ¸ì— ê´€í•œ í¬ìŠ¤íŠ¸\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\", # í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",     # LLM ê³µê²© ê¸°ë²•\n",
    "]\n",
    "\n",
    "# ì›¹ í˜ì´ì§€ ë¡œë”©\n",
    "print(\"ì›¹ í˜ì´ì§€ ë¡œë”© ì¤‘...\")\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]  # ë¦¬ìŠ¤íŠ¸ í‰íƒ„í™”\n",
    "print(f\"ì´ {len(docs_list)}ê°œ ë¬¸ì„œ ë¡œë”© ì™„ë£Œ\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í•  (tiktoken ê¸°ë°˜ - OpenAI í† í¬ë‚˜ì´ì € ì‚¬ìš©)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500,    # ê° ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜\n",
    "    chunk_overlap=0    # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” í† í° ìˆ˜ (0ìœ¼ë¡œ ì„¤ì •)\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "print(f\"ì´ {len(doc_splits)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ\")\n",
    "\n",
    "# Chroma ë²¡í„°ìŠ¤í† ì–´ì— ë¬¸ì„œ ì¶”ê°€ ë° ê²€ìƒ‰ê¸° ìƒì„±\n",
    "print(\"ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,           # ë¶„í• ëœ ë¬¸ì„œë“¤\n",
    "    collection_name=\"rag-chroma\",  # ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "    embedding=embd,                 # ì„ë² ë”© ëª¨ë¸\n",
    ")\n",
    "retriever = vectorstore.as_retriever()  # ê²€ìƒ‰ê¸° ê°ì²´ ìƒì„±\n",
    "print(\"ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52b427-750c-40f8-8893-e9caab3afd8d",
   "metadata": {},
   "source": [
    "## LLM ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28baefd-a961-49b0-8394-c5478dadda1c",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">LangChainì—ì„œ Pydantic ì‚¬ìš©</p>\n",
    "    <p>\n",
    "        ì´ ë…¸íŠ¸ë¶ì€ Pydantic v2 <code>BaseModel</code>ì„ ì‚¬ìš©í•˜ë¯€ë¡œ <code>langchain-core >= 0.3</code>ì´ í•„ìš”í•©ë‹ˆë‹¤. <code>langchain-core < 0.3</code> ì‚¬ìš© ì‹œ Pydantic v1ê³¼ v2 <code>BaseModel</code>ì˜ í˜¼ì¬ë¡œ ì¸í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd5ac0-fa18-4ee9-8051-062a0c56268f",
   "metadata": {},
   "source": [
    "### ì§ˆì˜ ë¶„ì„ì„ ìœ„í•œ ë¼ìš°í„° (Router for Query Analysis)\n",
    "\n",
    "ë¼ìš°íŒ…ë¶€í„° ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤. ë¨¼ì € LLMì— ì§ˆì˜ ë¶„ì„ì„ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "\n",
    "RouteQuery ë°ì´í„° ëª¨ë¸ì„ ìƒì„±í•˜ê³  LLMì— êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤. ë¼ìš°íŒ… ê²°ì •ì€ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë¬¸ì„œì˜ ì–´ë–¤ ë¶€ë¶„ì„ ì£¼ì œì— ë”°ë¼ RAGë¡œ ì—°ê²°í• ì§€ ëª…í™•íˆ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "LLMì´ RAG ë¬¸ì„œë¥¼ ë‹¤ì‹œ ìš”ì•½í•˜ë„ë¡ ìë™í™”í•  ìˆ˜ ìˆì§€ë§Œ, ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ë‹¤ë£° ë•ŒëŠ” ìë™í™”ê°€ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ë” ë¹„ìš© íš¨ìœ¨ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be",
   "metadata": {},
   "outputs": [],
   "source": "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\nprint(\"=== ë¼ìš°í„° í…ŒìŠ¤íŠ¸ ===\")\nprint(\"ì§ˆë¬¸ 1: 'Who will the Bears draft first in the NFL draft?'\")\nresult1 = question_router.invoke({\"question\": \"Who will the Bears draft first in the NFL draft?\"})\nprint(f\"ë¼ìš°íŒ… ê²°ê³¼: {result1.datasource}\")\nprint(\"\\nì§ˆë¬¸ 2: 'What are the types of agent memory?'\")\nresult2 = question_router.invoke({\"question\": \"What are the types of agent memory?\"})\nprint(f\"ë¼ìš°íŒ… ê²°ê³¼: {result2.datasource}\")\n\ndatasource='web_search'\ndatasource='vectorstore'"
  },
  {
   "cell_type": "markdown",
   "id": "cb248c94-0b0c-4d86-8565-32aa8d7424e4",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰ í‰ê°€ê¸° (Retrieval Grader)\n",
    "\n",
    "ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ í›„ ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì§ˆì˜ì— ë”°ë¼ RAGë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ì²˜ìŒì— ê²°ì •í–ˆì§€ë§Œ, ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ì§ˆì˜ì— ì¶©ë¶„íˆ ê´€ë ¨ì´ ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ìœ„í•´ LLMì— ì˜ì¡´í•˜ì—¬ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ê³ , ì´ì§„ 'yes' ë˜ëŠ” 'no' ê²°ì •ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856801cb-f42a-44e7-956f-47845e3664ca",
   "metadata": {},
   "outputs": [],
   "source": "print(f\"\\ní‰ê°€ ê²°ê³¼: {grade_result.binary_score}\")\n\nbinary_score='yes'"
  },
  {
   "cell_type": "markdown",
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "source": "print(f\"\\nìƒì„±ëœ ë‹µë³€:\\n{generation}\")\n\nAgent memory in LLM-powered autonomous systems consists of short-term and long-term memory. Short-term memory utilizes in-context learning for immediate tasks, while long-term memory allows agents to retain and recall information over extended periods, often using external storage for efficient retrieval. This memory structure supports the agent's ability to reflect on past actions and improve future performance."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë‹µë³€ ìƒì„± ì²´ì¸ êµ¬í˜„\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain Hubì—ì„œ ê²€ì¦ëœ RAG í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "# ì´ í”„ë¡¬í”„íŠ¸ëŠ” ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ë°›ì•„ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ë¨\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM ì„¤ì • (ë‹µë³€ ìƒì„±ìš©)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ë¬¸ì„œ ëª©ë¡ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©í•˜ëŠ” í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    \n",
    "    Args:\n",
    "        docs: ê²€ìƒ‰ëœ Document ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        \n",
    "    Returns:\n",
    "        str: ê° ë¬¸ì„œ ë‚´ìš©ì„ ë‘ ì¤„ ê°„ê²©ìœ¼ë¡œ ê²°í•©í•œ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±: í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ë¬¸ìì—´ íŒŒì„œ\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"=== RAG ì²´ì¸ í…ŒìŠ¤íŠ¸ ===\")\n",
    "docs_txt = format_docs(docs)  # ì´ì „ì— ê²€ìƒ‰í•œ ë¬¸ì„œë“¤ ì‚¬ìš©\n",
    "print(f\"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(docs_txt)} ë¬¸ì\")\n",
    "print(f\"ì§ˆë¬¸: {question}\")\n",
    "\n",
    "# ë‹µë³€ ìƒì„±\n",
    "generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "print(f\"\\nìƒì„±ëœ ë‹µë³€:\\n{generation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ab54a-4a4f-45fa-b1c5-cea1bf4c59d5",
   "metadata": {},
   "source": [
    "### í™˜ê° í‰ê°€ê¸° (Hallucination Grader)\n",
    "\n",
    "LLMì´ ê²€ìƒ‰ëœ ì‚¬ì‹¤ê³¼ ë¹„êµí•˜ì—¬ í™˜ê°ì„ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.  \n",
    "LLMì˜ í‰ê°€ë¥¼ ì´ì§„ 'yes' ë˜ëŠ” 'no' í˜•ì‹ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
   "metadata": {},
   "outputs": [],
   "source": "    print(\"âŒ ë‹µë³€ì— í™˜ê°ì´ë‚˜ ê·¼ê±° ì—†ëŠ” ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n\nGradeHallucinations(binary_score='yes')"
  },
  {
   "cell_type": "markdown",
   "id": "4f58502a-c25f-4d80-a402-5583b0cd3e41",
   "metadata": {},
   "source": [
    "### ë‹µë³€ í‰ê°€ê¸° (Answer Grader)\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ ë‹µë³€ì´ ì›ë˜ ì§ˆë¬¸ì— ì ì ˆíˆ ë‹µë³€í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded99680-437a-4c9d-b860-619c88949d84",
   "metadata": {},
   "outputs": [],
   "source": "    print(\"âŒ ë‹µë³€ì´ ì§ˆë¬¸ì„ ì¶©ë¶„íˆ í•´ê²°í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\")\n\nGradeAnswer(binary_score='yes')"
  },
  {
   "cell_type": "markdown",
   "id": "af77946c-2646-4039-86b0-e2fde1ab7459",
   "metadata": {},
   "source": [
    "### ì§ˆì˜ ì¬ì‘ì„± (Question Rewriting)\n",
    "\n",
    "ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ì´ RAGì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
    "í•˜ì§€ë§Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ RAGì— ì í•©í•œ í˜•íƒœê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "ê²€ìƒ‰ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë²¡í„° ìœ ì‚¬ì„± ê²€ìƒ‰ì— ë” ì í•©í•˜ë„ë¡ ì§ˆë¬¸ì„ ë‹¤ì‹œ í‘œí˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e",
   "metadata": {},
   "outputs": [],
   "source": "print(f\"ê°œì„ ëœ ì§ˆë¬¸: {rewritten_question}\")\n\n'What are the key concepts and techniques related to agent memory in artificial intelligence?'"
  },
  {
   "cell_type": "markdown",
   "id": "d07c0b31-b919-4498-869f-9673125c2473",
   "metadata": {},
   "source": [
    "## ì›¹ ê²€ìƒ‰ ë„êµ¬ (Web Search Tool)\n",
    "\n",
    "ì›¹ì—ì„œ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ Tavily Search ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d829bb-1074-4976-b650-ead41dcb9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n",
    "# k=3: ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "print(\"âœ… ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì • ì™„ë£Œ\")\n",
    "print(\"- ê²€ìƒ‰ ì—”ì§„: Tavily\")\n",
    "print(\"- ìµœëŒ€ ê²°ê³¼ ìˆ˜: 3ê°œ\")\n",
    "print(\"- ì‚¬ìš© ëª©ì : ìµœì‹  ì •ë³´ ë° ì‹¤ì‹œê°„ ë°ì´í„° ê²€ìƒ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ êµ¬ì„± (Construct the Graph)\n",
    "\n",
    "íë¦„ì„ ê·¸ë˜í”„ë¡œ ìº¡ì²˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜ (Define Graph State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723fcdb-06e6-402d-912e-899795b78408",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    ìš°ë¦¬ ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "    Attributes:\n",
    "        question: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        generation: LLM ìƒì„± ë‹µë³€\n",
    "        documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    question: str          # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸\n",
    "    generation: str        # ìƒì„±ëœ ë‹µë³€\n",
    "    documents: List[str]   # ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ìƒíƒœ êµ¬ì„± ìš”ì†Œ:\")\n",
    "print(\"- question: ì‚¬ìš©ìì˜ ì§ˆë¬¸\")\n",
    "print(\"- generation: AIê°€ ìƒì„±í•œ ë‹µë³€\")\n",
    "print(\"- documents: ê²€ìƒ‰ëœ ì°¸ì¡° ë¬¸ì„œë“¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d6c0d-42e8-4399-9751-e315be16607a",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ í”Œë¡œìš° ì •ì˜ (Define Graph Flow)\n",
    "\n",
    "ê° ë…¸ë“œì™€ ì—£ì§€ì˜ ë™ì‘ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê·¸ë˜í”„ ë…¸ë“œ í•¨ìˆ˜ë“¤ ì •ì˜\n",
    "\n",
    "from pprint import pprint\n",
    "from langchain.schema import Document\n",
    "\n",
    "# === í•µì‹¬ ì²˜ë¦¬ ë…¸ë“œë“¤ ===\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): documents í‚¤ì— ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ì¶”ê°€ëœ ìƒˆë¡œìš´ ìƒíƒœ\n",
    "    \"\"\"\n",
    "    print(\"---ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    documents = retriever.invoke(question)\n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ\")\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): generation í‚¤ì— LLM ìƒì„± ë‹µë³€ì´ ì¶”ê°€ëœ ìƒˆë¡œìš´ ìƒíƒœ\n",
    "    \"\"\"\n",
    "    print(\"---ë‹µë³€ ìƒì„± ìˆ˜í–‰---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    docs_txt = format_docs(documents)\n",
    "    generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
    "    print(f\"ìƒì„±ëœ ë‹µë³€ ê¸¸ì´: {len(generation)}ì\")\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œë“¤ë§Œ í•„í„°ë§í•˜ì—¬ documents í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    print(\"---ë¬¸ì„œ ê´€ë ¨ì„± ê²€ì‚¬---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ê° ë¬¸ì„œë³„ë¡œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
    "    filtered_docs = []\n",
    "    for i, d in enumerate(documents):\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(f\"---í‰ê°€: ë¬¸ì„œ {i+1} ê´€ë ¨ì„± ìˆìŒ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(f\"---í‰ê°€: ë¬¸ì„œ {i+1} ê´€ë ¨ì„± ì—†ìŒ---\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"í•„í„°ë§ ê²°ê³¼: {len(documents)}ê°œ â†’ {len(filtered_docs)}ê°œ\")\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    ë” ë‚˜ì€ ê²€ìƒ‰ì„ ìœ„í•´ ì§ˆë¬¸ì„ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): ì¬ì‘ì„±ëœ ì§ˆë¬¸ìœ¼ë¡œ question í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    print(\"---ì§ˆì˜ ë³€í™˜ ìˆ˜í–‰---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    print(f\"ì›ë˜ ì§ˆë¬¸: {question}\")\n",
    "    print(f\"ê°œì„ ëœ ì§ˆë¬¸: {better_question}\")\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    ì¬ì‘ì„±ëœ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        state (dict): ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¡œ documents í‚¤ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    print(\"---ì›¹ ê²€ìƒ‰ ìˆ˜í–‰---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    print(f\"ì›¹ ê²€ìƒ‰ ê²°ê³¼ ê¸¸ì´: {len(web_results.page_content)}ì\")\n",
    "\n",
    "    return {\"documents\": web_results, \"question\": question}\n",
    "\n",
    "\n",
    "# === ì¡°ê±´ë¶€ ë¶„ê¸° í•¨ìˆ˜ë“¤ ===\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ ë˜ëŠ” RAGë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: í˜¸ì¶œí•  ë‹¤ìŒ ë…¸ë“œ ì´ë¦„\n",
    "    \"\"\"\n",
    "    print(\"---ì§ˆì˜ ë¼ìš°íŒ…---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    \n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"---ì§ˆì˜ë¥¼ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¼ìš°íŒ…---\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ì§ˆì˜ë¥¼ RAGë¡œ ë¼ìš°íŒ…---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    ë‹µë³€ ìƒì„±ì„ í• ì§€, ì•„ë‹ˆë©´ ì§ˆë¬¸ì„ ì¬ìƒì„±í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: í˜¸ì¶œí•  ë‹¤ìŒ ë…¸ë“œì— ëŒ€í•œ ì´ì§„ ê²°ì •\n",
    "    \"\"\"\n",
    "    print(\"---í‰ê°€ëœ ë¬¸ì„œë“¤ ê²€í† ---\")\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ê²€ì‚¬ì—ì„œ í•„í„°ë§ë¨\n",
    "        # ìƒˆë¡œìš´ ì§ˆì˜ë¥¼ ì¬ìƒì„±í•  ê²ƒ\n",
    "        print(\"---ê²°ì •: ëª¨ë“  ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ìŒ, ì§ˆì˜ ë³€í™˜ ìˆ˜í–‰---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # ê´€ë ¨ ë¬¸ì„œê°€ ìˆìœ¼ë¯€ë¡œ ë‹µë³€ ìƒì„±\n",
    "        print(\"---ê²°ì •: ê´€ë ¨ ë¬¸ì„œ ì¡´ì¬, ë‹µë³€ ìƒì„±---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ë‹µë³€ì´ ë¬¸ì„œì— ê·¼ê±°í•˜ê³  ìˆê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        state (dict): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ\n",
    "\n",
    "    Returns:\n",
    "        str: í˜¸ì¶œí•  ë‹¤ìŒ ë…¸ë“œì— ëŒ€í•œ ê²°ì •\n",
    "    \"\"\"\n",
    "    print(\"---í™˜ê° ê²€ì‚¬---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # í™˜ê° ê²€ì‚¬\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---ê²°ì •: ìƒì„± ê²°ê³¼ê°€ ë¬¸ì„œì— ê·¼ê±°í•¨---\")\n",
    "        # ì§ˆë¬¸-ë‹µë³€ ì í•©ì„± ê²€ì‚¬\n",
    "        print(\"---ì§ˆë¬¸ ëŒ€ë¹„ ìƒì„± ê²°ê³¼ í‰ê°€---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---ê²°ì •: ìƒì„± ê²°ê³¼ê°€ ì§ˆë¬¸ì— ì ì ˆíˆ ë‹µë³€í•¨---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---ê²°ì •: ìƒì„± ê²°ê³¼ê°€ ì§ˆë¬¸ì— ë‹µë³€í•˜ì§€ ëª»í•¨---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"---ê²°ì •: ìƒì„± ê²°ê³¼ê°€ ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•ŠìŒ, ì¬ì‹œë„---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ê·¸ë˜í”„ ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì»´íŒŒì¼ (Compile Graph)\n",
    "\n",
    "ì •ì˜ëœ ë…¸ë“œë“¤ê³¼ ì—£ì§€ë“¤ì„ í•˜ë‚˜ì˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œë¡œ ì¡°í•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê·¸ë˜í”„ ì›Œí¬í”Œë¡œ êµ¬ì„± ë° ì»´íŒŒì¼\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# StateGraph ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# === ë…¸ë“œ ì¶”ê°€ ===\n",
    "# ê° ë…¸ë“œëŠ” íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ì™€ ì—°ê²°ë©ë‹ˆë‹¤\n",
    "workflow.add_node(\"web_search\", web_search)           # ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n",
    "workflow.add_node(\"retrieve\", retrieve)               # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ë…¸ë“œ\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "workflow.add_node(\"generate\", generate)               # ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "workflow.add_node(\"transform_query\", transform_query) # ì§ˆì˜ ë³€í™˜ ë…¸ë“œ\n",
    "\n",
    "# === ì—£ì§€ êµ¬ì„± ===\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: ì‹œì‘ì ì—ì„œ ë¼ìš°íŒ… ê²°ì •\n",
    "workflow.add_conditional_edges(\n",
    "    START,           # ì‹œì‘ì \n",
    "    route_question,  # ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "    {\n",
    "        \"web_search\": \"web_search\",    # ì›¹ ê²€ìƒ‰ ê²½ë¡œ\n",
    "        \"vectorstore\": \"retrieve\",     # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ê²½ë¡œ\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê³ ì • ì—£ì§€: ì›¹ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "\n",
    "# ê³ ì • ì—£ì§€: ë¬¸ì„œ ê²€ìƒ‰ â†’ ë¬¸ì„œ í‰ê°€\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: ë¬¸ì„œ í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸°\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",    # ë¬¸ì„œ í‰ê°€ ë…¸ë“œ\n",
    "    decide_to_generate,   # ìƒì„± ì—¬ë¶€ ê²°ì • í•¨ìˆ˜\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # ì§ˆì˜ ë³€í™˜ ê²½ë¡œ\n",
    "        \"generate\": \"generate\",                # ë‹µë³€ ìƒì„± ê²½ë¡œ\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê³ ì • ì—£ì§€: ì§ˆì˜ ë³€í™˜ â†’ ì¬ê²€ìƒ‰\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: ë‹µë³€ ìƒì„± í›„ í’ˆì§ˆ í‰ê°€\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",                                    # ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "    grade_generation_v_documents_and_question,    # í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜\n",
    "    {\n",
    "        \"not supported\": \"generate\",        # ì¬ìƒì„± (í™˜ê° ë°œê²¬ì‹œ)\n",
    "        \"useful\": END,                      # ì¢…ë£Œ (ì„±ê³µ)\n",
    "        \"not useful\": \"transform_query\",   # ì§ˆì˜ ë³€í™˜ í›„ ì¬ì‹œë„\n",
    "    },\n",
    ")\n",
    "\n",
    "# ì›Œí¬í”Œë¡œ ì»´íŒŒì¼ - ì‹¤í–‰ ê°€ëŠ¥í•œ ì•±ìœ¼ë¡œ ë³€í™˜\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"âœ… ì ì‘í˜• RAG ì›Œí¬í”Œë¡œ ì»´íŒŒì¼ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ”„ ì›Œí¬í”Œë¡œ êµ¬ì¡°:\")\n",
    "print(\"1. START â†’ ì§ˆì˜ ë¼ìš°íŒ… (ì›¹ê²€ìƒ‰ vs ë²¡í„°ìŠ¤í† ì–´)\")\n",
    "print(\"2. ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ: ê²€ìƒ‰ â†’ ë¬¸ì„œí‰ê°€ â†’ ìƒì„± ì—¬ë¶€ ê²°ì •\")\n",
    "print(\"3. ì›¹ê²€ìƒ‰ ê²½ë¡œ: ì›¹ê²€ìƒ‰ â†’ ë‹µë³€ìƒì„±\")\n",
    "print(\"4. í’ˆì§ˆ ê²€ì¦: í™˜ê°ê²€ì‚¬ â†’ ë‹µë³€ì í•©ì„±ê²€ì‚¬ â†’ END\")\n",
    "print(\"5. ìë™ ì¬ì‹œë„: í’ˆì§ˆ ë¯¸ë‹¬ì‹œ ì§ˆì˜ë³€í™˜ â†’ ì¬ê²€ìƒ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bce541",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‚¬ìš© (Use Graph)\n",
    "\n",
    "êµ¬ì„±ëœ ì ì‘í˜• RAG ì‹œìŠ¤í…œì„ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acc541-d726-4b75-84d1-a215845fe88a",
   "metadata": {},
   "outputs": [],
   "source": "# ìµœì¢… ìƒì„± ê²°ê³¼ ì¶œë ¥\nprint(\"ğŸ“ ìµœì¢… ë‹µë³€:\")\npprint(value[\"generation\"])\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n---ROUTE QUESTION---\n---ROUTE QUESTION TO WEB SEARCH---\n---WEB SEARCH---\n\"Node 'web_search':\"\n'\\n---\\n'\n---GENERATE---\n---CHECK HALLUCINATIONS---\n---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n---GRADE GENERATION vs QUESTION---\n---DECISION: GENERATION ADDRESSES QUESTION---\n\"Node 'generate':\"\n'\\n---\\n'\n('The Chicago Bears are expected to draft quarterback Caleb Williams first '\n 'overall in the 2024 NFL Draft. They also have a second first-round pick, '\n 'where they selected wide receiver Rome Odunze.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
   "metadata": {},
   "outputs": [],
   "source": "print(\"- ìë™ ë¼ìš°íŒ… ë° ìê¸° ìˆ˜ì • ë©”ì»¤ë‹ˆì¦˜ í™•ì¸ë¨\")\n\n---ROUTE QUESTION---\n---ROUTE QUESTION TO RAG---\n---RETRIEVE---\n\"Node 'retrieve':\"\n'\\n---\\n'\n---CHECK DOCUMENT RELEVANCE TO QUESTION---\n---GRADE: DOCUMENT NOT RELEVANT---\n---GRADE: DOCUMENT RELEVANT---\n---GRADE: DOCUMENT NOT RELEVANT---\n---GRADE: DOCUMENT RELEVANT---\n---ASSESS GRADED DOCUMENTS---\n---DECISION: GENERATE---\n\"Node 'grade_documents':\"\n'\\n---\\n'\n---GENERATE---\n---CHECK HALLUCINATIONS---\n---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n---GRADE GENERATION vs QUESTION---\n---DECISION: GENERATION ADDRESSES QUESTION---\n\"Node 'generate':\"\n'\\n---\\n'\n('The types of agent memory include short-term memory, long-term memory, and '\n 'sensory memory. Short-term memory is utilized for in-context learning, while '\n 'long-term memory allows for the retention and recall of information over '\n 'extended periods. Sensory memory involves learning embedding representations '\n 'for various raw inputs, such as text and images.')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}